{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from autofeat import AutoFeatClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ignore all future warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "np.seterr(divide = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same interface for loading all datasets\n",
    "def load_classification_dataset(name):\n",
    "    # load one of the datasets as X and y\n",
    "    units = {}\n",
    "    if name == \"iris\":\n",
    "        # sklearn iris housing dataset\n",
    "        X, y = load_iris(True)\n",
    "\n",
    "    elif name == \"wine\":\n",
    "        # sklearn wine dataset\n",
    "        X, y = load_wine(True)\n",
    "    \n",
    "    elif name == \"breast_cancer\":\n",
    "        # sklearn breast_cancer dataset\n",
    "        X, y = load_breast_cancer(True)\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown dataset %r\" % name)\n",
    "    return np.array(X, dtype=float), np.array(y, dtype=float), units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(X, y, model, param_grid):\n",
    "    # load data\n",
    "    #X, y, _ = load_classification_dataset(dataset)\n",
    "    # split in training and test parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "    \n",
    "    if model.__class__.__name__ == \"SVC\":\n",
    "        sscaler = StandardScaler()\n",
    "        X_train = sscaler.fit_transform(X_train)\n",
    "        X_test = sscaler.transform(X_test)\n",
    "    \n",
    "    # train model on train split incl cross-validation for parameter selection\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        gsmodel = GridSearchCV(model, param_grid, cv=5)\n",
    "        gsmodel.fit(X_train, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"Acc. on training data:\", accuracy_score(y_train, gsmodel.predict(X_train)))\n",
    "    print(\"Acc. on test data:\", accuracy_score(y_test, gsmodel.predict(X_test)))\n",
    "    return gsmodel.best_estimator_\n",
    "\n",
    "def test_autofeat(X, y, units, feateng_steps=2):\n",
    "    # load data\n",
    "    #X, y, units = load_classification_dataset(dataset)\n",
    "    # split in training and test parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "    # run autofeat\n",
    "    afclas = AutoFeatClassifier(verbose=1, feateng_steps=feateng_steps, units=units)\n",
    "    # fit autofeat on less data, otherwise ridge reg model with xval will overfit on new features\n",
    "    X_train_tr = afclas.fit_transform(X_train, y_train)\n",
    "    X_test_tr = afclas.transform(X_test)\n",
    "    print(\"autofeat new features:\", len(afclas.new_feat_cols_))\n",
    "    print(\"autofeat Acc. on training data:\", accuracy_score(y_train, afclas.predict(X_train_tr)))\n",
    "    print(\"autofeat Acc. on test data:\", accuracy_score(y_test, afclas.predict(X_test_tr)))\n",
    "    \n",
    "    # train rreg on transformed train split incl cross-validation for parameter selection\n",
    "    print(\"# Logistic Regression\")\n",
    "    rreg = LogisticRegression(class_weight=\"balanced\")\n",
    "    param_grid = {\"C\": np.logspace(-4, 4, 10)}\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        gsmodel = GridSearchCV(rreg, param_grid, cv=5)\n",
    "        gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"Acc. on training data:\", accuracy_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"Acc. on test data:\", accuracy_score(y_test, gsmodel.predict(X_test_tr)))\n",
    "    \n",
    "    print(\"# Random Forest\")\n",
    "    rforest = RandomForestClassifier(n_estimators=100, random_state=13)\n",
    "    param_grid = {\"min_samples_leaf\": [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2]}\n",
    "    gsmodel = GridSearchCV(rforest, param_grid, cv=5)\n",
    "    gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"Acc. on training data:\", accuracy_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"Acc. on test data:\", accuracy_score(y_test, gsmodel.predict(X_test_tr)))\n",
    "    \n",
    "    print(\"# SVC\")\n",
    "    svc = SVC(gamma=\"scale\", class_weight=\"balanced\")\n",
    "    param_grid = {\"C\": [1., 10., 25., 50., 100., 250.]}\n",
    "    sscaler = StandardScaler()\n",
    "    X_train_tr = sscaler.fit_transform(X_train_tr)\n",
    "    X_test_tr = sscaler.transform(X_test_tr)\n",
    "    gsmodel = GridSearchCV(svc, param_grid, cv=5)\n",
    "    gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"Acc. on training data:\", accuracy_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"Acc. on test data:\", accuracy_score(y_test, gsmodel.predict(X_test_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### breast_cancer\n",
      "(569, 30) [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "dsname = 'breast_cancer'\n",
    "print(\"####\", dsname)\n",
    "X, y, units = load_classification_dataset(dsname)\n",
    "print(X.shape, np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat] The 1 step feature engineering process could generate up to 210 features.\n",
      "[AutoFeat] With 569 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 155 transformed features from 30 original features - done.\n",
      "[feateng] Generated altogether 164 new features in 1 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 61 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 15 features after 5 feature selection runs\n",
      "[featsel] 11 features after correlation filtering\n",
      "[featsel] 9 features after noise filtering\n",
      "[AutoFeat] Computing 3 new features.\n",
      "[AutoFeat]     3/    3 new features ...done.\n",
      "[AutoFeat] Final dataframe with 33 feature columns (3 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[48.79554455]\n",
      "40.935312 * x024\n",
      "38.862581 * x027\n",
      "16.491117 * x028\n",
      "11.588957 * 1/x013\n",
      "10.904415 * x010\n",
      "1.194381 * x020\n",
      "0.330466 * x021\n",
      "0.170626 * 1/x023\n",
      "0.040552 * 1/x018\n",
      "[AutoFeat] Final score: 0.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#új változók generálása autofeattel\n",
    "afclas = AutoFeatClassifier(verbose=1, feateng_steps=1, units=units)\n",
    "# fit autofeat on less data, otherwise ridge reg model with xval will overfit on new features\n",
    "X_af = afclas.fit_transform(X, y)\n",
    "X_af.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#randomforest illesztése a kibővített adathalmazra, hogy feature importance-t alkalmazzunk rajta\n",
    "randforclas = RandomForestClassifier(random_state=13)\n",
    "randforclas.fit(X_af, y)\n",
    "#feature importance alkalmazása és ábrázolása\n",
    "importances = randforclas.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.bar(range(X_af.shape[1]), importances[indices])\n",
    "plt.xticks(range(X_af.shape[1]), indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = []\n",
    "columns=[]\n",
    "#kiválasztom a legfontosabb featureket\n",
    "for i,v in enumerate(importances):\n",
    "    if v > 0.08:\n",
    "        select.append(i)\n",
    "for i in select:\n",
    "    columns.append(X_af.columns[i])\n",
    "XS_af = X_af[columns]\n",
    "XS_af.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### breast_cancer\n",
      "best params: {'C': 1291.5496650148827}\n",
      "best score: 0.9538461538461538\n",
      "Acc. on training data: 0.9582417582417583\n",
      "Acc. on test data: 0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "print(\"####\", dsname)\n",
    "rreg = LogisticRegression(class_weight=\"balanced\")\n",
    "params = {\"C\": np.logspace(-4, 4, 10)}\n",
    "rreg = test_model(XS_af, y, rreg, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### breast_cancer\n",
      "best params: {'min_samples_leaf': 0.0001}\n",
      "best score: 0.9494505494505494\n",
      "Acc. on training data: 1.0\n",
      "Acc. on test data: 0.9035087719298246\n"
     ]
    }
   ],
   "source": [
    "print(\"####\", dsname)\n",
    "rforest = RandomForestClassifier(n_estimators=100, random_state=13)\n",
    "params = {\"min_samples_leaf\": [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2]}\n",
    "rforest = test_model(XS_af, y, rforest, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### breast_cancer\n",
      "best params: {'C': 100.0}\n",
      "best score: 0.956043956043956\n",
      "Acc. on training data: 0.9604395604395605\n",
      "Acc. on test data: 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "print(\"####\", dsname)\n",
    "svc = SVC(gamma=\"scale\", class_weight=\"balanced\")\n",
    "params = {\"C\": [1., 10., 25., 50., 100., 250.]}\n",
    "svc = test_model(XS_af, y, svc, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### breast_cancer\n",
      "[AutoFeat] The 1 step feature engineering process could generate up to 35 features.\n",
      "[AutoFeat] With 455 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 21 transformed features from 5 original features - done.\n",
      "[feateng] Generated altogether 25 new features in 1 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 10 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 6 features after 5 feature selection runs\n",
      "[featsel] 4 features after correlation filtering\n",
      "[featsel] 4 features after noise filtering\n",
      "[AutoFeat] Computing 1 new features.\n",
      "[AutoFeat]     1/    1 new features ...done.\n",
      "[AutoFeat] Final dataframe with 6 feature columns (1 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[20.91807752]\n",
      "31.229854 * x027\n",
      "2.633877 * x027**3\n",
      "0.157116 * x022\n",
      "0.033982 * 1/x023\n",
      "[AutoFeat] Final score: 0.9407\n",
      "[AutoFeat] Computing 1 new features.\n",
      "[AutoFeat]     1/    1 new features ...done.\n",
      "autofeat new features: 1\n",
      "autofeat Acc. on training data: 0.9406593406593406\n",
      "autofeat Acc. on test data: 0.9122807017543859\n",
      "# Logistic Regression\n",
      "best params: {'C': 10000.0}\n",
      "best score: 0.9516483516483516\n",
      "Acc. on training data: 0.9582417582417583\n",
      "Acc. on test data: 0.9298245614035088\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.01}\n",
      "best score: 0.9516483516483516\n",
      "Acc. on training data: 0.967032967032967\n",
      "Acc. on test data: 0.9210526315789473\n",
      "# SVC\n",
      "best params: {'C': 50.0}\n",
      "best score: 0.956043956043956\n",
      "Acc. on training data: 0.9604395604395605\n",
      "Acc. on test data: 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "print(\"####\", dsname)\n",
    "test_autofeat(XS_af, y, units, feateng_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### breast_cancer\n",
      "[AutoFeat] The 2 step feature engineering process could generate up to 630 features.\n",
      "[AutoFeat] With 455 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 21 transformed features from 5 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng] Generated 311 feature combinations from 325 original feature tuples - done.\n",
      "[feateng] Generated altogether 343 new features in 2 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 76 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 7 features after 5 feature selection runs\n",
      "[featsel] 5 features after correlation filtering\n",
      "[featsel] 3 features after noise filtering\n",
      "[AutoFeat] Final dataframe with 5 feature columns (0 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[20.91746357]\n",
      "31.343143 * x027\n",
      "0.157040 * x022\n",
      "0.022155 * 1/x023\n",
      "[AutoFeat] Final score: 0.9407\n",
      "autofeat new features: 0\n",
      "autofeat Acc. on training data: 0.9406593406593406\n",
      "autofeat Acc. on test data: 0.9122807017543859\n",
      "# Logistic Regression\n",
      "best params: {'C': 1291.5496650148827}\n",
      "best score: 0.9538461538461538\n",
      "Acc. on training data: 0.9582417582417583\n",
      "Acc. on test data: 0.9298245614035088\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.0001}\n",
      "best score: 0.9494505494505494\n",
      "Acc. on training data: 1.0\n",
      "Acc. on test data: 0.9035087719298246\n",
      "# SVC\n",
      "best params: {'C': 100.0}\n",
      "best score: 0.956043956043956\n",
      "Acc. on training data: 0.9604395604395605\n",
      "Acc. on test data: 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "print(\"####\", dsname)\n",
    "test_autofeat(XS_af, y, units, feateng_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### breast_cancer\n",
      "[AutoFeat] The 3 step feature engineering process could generate up to 14910 features.\n",
      "[AutoFeat] With 455 data points this new feature matrix would use about 0.03 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 21 transformed features from 5 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng] Generated 1245 feature combinations from 325 original feature tuples - done.\n",
      "[feateng] Step 3: transformation of new features\n",
      "[feateng] Generated 4662 transformed features from 1245 original features - done.\n",
      "[feateng] Generated altogether 6945 new features in 3 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 1949 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 16 features after 5 feature selection runs\n",
      "[featsel] 7 features after correlation filtering\n",
      "[featsel] 6 features after noise filtering\n",
      "[AutoFeat] Computing 3 new features.\n",
      "[AutoFeat]     3/    3 new features ...done.\n",
      "[AutoFeat] Final dataframe with 8 feature columns (3 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[17.18787048]\n",
      "76.972402 * Abs(x027**2 - 1/x022)\n",
      "69.582885 * x007\n",
      "14.095964 * Abs(x027**3 - 1/x022)\n",
      "0.146398 * 1/x023\n",
      "0.078478 * x022\n",
      "0.006433 * 1/(x007**3 + x1x023)\n",
      "[AutoFeat] Final score: 0.9582\n",
      "[AutoFeat] Computing 3 new features.\n",
      "[AutoFeat]     3/    3 new features ...done.\n",
      "autofeat new features: 3\n",
      "autofeat Acc. on training data: 0.9582417582417583\n",
      "autofeat Acc. on test data: 0.9122807017543859\n",
      "# Logistic Regression\n",
      "best params: {'C': 10000.0}\n",
      "best score: 0.9538461538461538\n",
      "Acc. on training data: 0.9494505494505494\n",
      "Acc. on test data: 0.9035087719298246\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.01}\n",
      "best score: 0.9582417582417582\n",
      "Acc. on training data: 0.9692307692307692\n",
      "Acc. on test data: 0.9210526315789473\n",
      "# SVC\n",
      "best params: {'C': 50.0}\n",
      "best score: 0.9538461538461538\n",
      "Acc. on training data: 0.9604395604395605\n",
      "Acc. on test data: 0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "print(\"####\", dsname)\n",
    "test_autofeat(XS_af, y, units, feateng_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
