{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install autofeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston, load_diabetes\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from autofeat import AutoFeatRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ignore all future warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "np.seterr(divide = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regr adatbeolvasó fv.\n",
    "def load_regression_dataset(name):\n",
    "    units = {}\n",
    "    if name == \"boston\":\n",
    "        X, y = load_boston(True)\n",
    "    elif name == \"diabetes\":\n",
    "        X, y = load_diabetes(True)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown dataset %r\" % name)\n",
    "    return np.array(X, dtype=float), np.array(y, dtype=float), units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#módosított modell tesztelő fv.\n",
    "def test_model(X, y, model, param_grid):\n",
    "    # load data\n",
    "    #X, y, _ = load_regression_dataset(dataset)\n",
    "    # split in training and test parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "    \n",
    "    if model.__class__.__name__ == \"SVR\":\n",
    "        sscaler = StandardScaler()\n",
    "        X_train = sscaler.fit_transform(X_train)\n",
    "        X_test = sscaler.transform(X_test)\n",
    "        \n",
    "    # train model on train split incl cross-validation for parameter selection\n",
    "    gsmodel = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "    gsmodel.fit(X_train, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"MSE on training data:\", mean_squared_error(y_train, gsmodel.predict(X_train)))\n",
    "    print(\"MSE on test data:\", mean_squared_error(y_test, gsmodel.predict(X_test)))\n",
    "    print(\"R^2 on training data:\", r2_score(y_train, gsmodel.predict(X_train)))\n",
    "    print(\"R^2 on test data:\", r2_score(y_test, gsmodel.predict(X_test)))\n",
    "    return gsmodel.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#módosított autofeat modell tesztelő fv.\n",
    "def test_autofeat(X, y, units, feateng_steps=2):\n",
    "    # load data\n",
    "    #X, y, units = load_regression_dataset(dataset)\n",
    "    # split in training and test parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "    # run autofeat\n",
    "    afreg = AutoFeatRegressor(verbose=1, feateng_steps=feateng_steps, units=units)\n",
    "    # fit autofeat on less data, otherwise ridge reg model with xval will overfit on new features\n",
    "    X_train_tr = afreg.fit_transform(X_train, y_train)\n",
    "    X_test_tr = afreg.transform(X_test)\n",
    "    print(\"autofeat new features:\", len(afreg.new_feat_cols_))\n",
    "    print(\"autofeat MSE on training data:\", mean_squared_error(y_train, afreg.predict(X_train_tr)))\n",
    "    print(\"autofeat MSE on test data:\", mean_squared_error(y_test, afreg.predict(X_test_tr)))\n",
    "    print(\"autofeat R^2 on training data:\", r2_score(y_train, afreg.predict(X_train_tr)))\n",
    "    print(\"autofeat R^2 on test data:\", r2_score(y_test, afreg.predict(X_test_tr)))\n",
    "    \n",
    "    \n",
    "    # train rreg on transformed train split incl cross-validation for parameter selection\n",
    "    print(\"# Ridge Regression\")\n",
    "    rreg = Ridge()\n",
    "    param_grid = {\"alpha\": [0.00001, 0.0001, 0.001, 0.01, 0.1, 1., 2.5, 5., 10., 25., 50., 100., 250., 500., 1000., 2500., 5000., 10000.]}\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        gsmodel = GridSearchCV(rreg, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "        gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"MSE on training data:\", mean_squared_error(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"MSE on test data:\", mean_squared_error(y_test, gsmodel.predict(X_test_tr)))\n",
    "    print(\"R^2 on training data:\", r2_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"R^2 on test data:\", r2_score(y_test, gsmodel.predict(X_test_tr)))\n",
    "    \n",
    "    \n",
    "    print(\"# Random Forest\")\n",
    "    rforest = RandomForestRegressor(n_estimators=100, random_state=13)\n",
    "    param_grid = {\"min_samples_leaf\": [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2]}\n",
    "    gsmodel = GridSearchCV(rforest, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "    gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"MSE on training data:\", mean_squared_error(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"MSE on test data:\", mean_squared_error(y_test, gsmodel.predict(X_test_tr)))\n",
    "    print(\"R^2 on training data:\", r2_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"R^2 on test data:\", r2_score(y_test, gsmodel.predict(X_test_tr)))\n",
    "    \n",
    "    print(\"# SVR\")\n",
    "    svr = SVR(gamma=\"scale\")\n",
    "    param_grid = {\"C\": [1., 10., 25., 50., 100., 250.]}\n",
    "    sscaler = StandardScaler()\n",
    "    X_train_tr = sscaler.fit_transform(X_train_tr)\n",
    "    X_test_tr = sscaler.transform(X_test_tr)\n",
    "\n",
    "    gsmodel = GridSearchCV(svr, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "    gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"MSE on training data:\", mean_squared_error(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"MSE on test data:\", mean_squared_error(y_test, gsmodel.predict(X_test_tr)))\n",
    "    print(\"R^2 on training data:\", r2_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"R^2 on test data:\", r2_score(y_test, gsmodel.predict(X_test_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### diabetes\n",
      "(442, 10)\n"
     ]
    }
   ],
   "source": [
    "#adatok beolvasása és splitelése\n",
    "dsname = 'diabetes'\n",
    "print(\"####\", dsname)\n",
    "X, y, units = load_regression_dataset(dsname)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#randomforest illesztése a kibővített adathalmazra, hogy feature importance-t alkalmazzunk rajta\n",
    "randforreg = RandomForestRegressor(random_state=13)\n",
    "randforreg.fit(X, y)\n",
    "#feature importance alkalmazása és ábrázolása\n",
    "importances = randforreg.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.bar(range(X.shape[1]), importances[indices])\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = []\n",
    "#kiválasztom a legfontosabb featureket\n",
    "for i,v in enumerate(importances):\n",
    "    if v > 0.2:\n",
    "        select.append(i)\n",
    "XS = X[:,select]\n",
    "XS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat] The 1 step feature engineering process could generate up to 14 features.\n",
      "[AutoFeat] With 442 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 10 transformed features from 2 original features - done.\n",
      "[feateng] Generated altogether 10 new features in 1 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 8 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 5 features after 5 feature selection runs\n",
      "[featsel] 5 features after correlation filtering\n",
      "[featsel] 4 features after noise filtering\n",
      "[AutoFeat] Computing 2 new features.\n",
      "[AutoFeat]     2/    2 new features ...done.\n",
      "[AutoFeat] Final dataframe with 4 feature columns (2 new).\n",
      "[AutoFeat] Training final regression model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "150.50962424221956\n",
      "716.322118 * x000**2\n",
      "592.345690 * x000\n",
      "564.152217 * x001\n",
      "0.004590 * 1/x001\n",
      "[AutoFeat] Final score: 0.4611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(442, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#új változók generálása autofeattel\n",
    "afreg = AutoFeatRegressor(verbose=1, feateng_steps=1, units=units)\n",
    "#és a legjobbak kiválasztása\n",
    "XS_af = afreg.fit_transform(XS, y)\n",
    "XS_af.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#randomforest illesztése a kibővített adathalmazra, hogy feature importance-t alkalmazzunk rajta\n",
    "randforreg = RandomForestRegressor(random_state=13)\n",
    "randforreg.fit(XS_af, y)\n",
    "#feature importance alkalmazása és ábrázolása\n",
    "importances = randforreg.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.bar(range(XS_af.shape[1]), importances[indices])\n",
    "plt.xticks(range(XS_af.shape[1]), indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = []\n",
    "columns=[]\n",
    "#kiválasztom a legfontosabb featureket\n",
    "for i,v in enumerate(importances):\n",
    "    if v > 0.25:\n",
    "        select.append(i)\n",
    "for i in select:\n",
    "    columns.append(XS_af.columns[i])\n",
    "#leszúkitem a fontos featurekkel az adathalmazt\n",
    "XSS_af = XS_af[columns]\n",
    "XSS_af.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adathalmaz tesztelése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsname='diabetes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### diabetes\n",
      "best params: {'alpha': 0.01}\n",
      "best score: -3277.0593286152516\n",
      "MSE on training data: 3188.356809815925\n",
      "MSE on test data: 3279.342677568209\n",
      "R^2 on training data: 0.48095707165436086\n",
      "R^2 on test data: 0.3514223582171675\n"
     ]
    }
   ],
   "source": [
    "#Ridge regresszió\n",
    "print(\"####\", dsname)\n",
    "rreg = Ridge()\n",
    "params = {\"alpha\": [0.00001, 0.0001, 0.001, 0.01, 0.1, 1., 2.5, 5., 10., 25., 50., 100., 250., 500., 1000., 2500., 5000., 10000., 25000., 50000., 100000.]}\n",
    "rreg = test_model(XSS_af, y, rreg, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### diabetes\n",
      "best params: {'C': 50.0}\n",
      "best score: -3357.35932007566\n",
      "MSE on training data: 3054.0818246742056\n",
      "MSE on test data: 3404.522560802321\n",
      "R^2 on training data: 0.502816131241719\n",
      "R^2 on test data: 0.32666469137680054\n"
     ]
    }
   ],
   "source": [
    "#SVR regresszió\n",
    "print(\"####\", dsname)\n",
    "svr = SVR(gamma=\"scale\")\n",
    "params = {\"C\": [1., 10., 25., 50., 100., 250.]}\n",
    "svr = test_model(XSS_af, y, svr, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### diabetes\n",
      "best params: {'min_samples_leaf': 0.05}\n",
      "best score: -3375.0127427729058\n",
      "MSE on training data: 2777.476364452161\n",
      "MSE on test data: 3324.3099104024823\n",
      "R^2 on training data: 0.5478456297056415\n",
      "R^2 on test data: 0.3425288863550626\n"
     ]
    }
   ],
   "source": [
    "#random forest regresszió\n",
    "print(\"####\", dsname)\n",
    "rforest = RandomForestRegressor(n_estimators=100, random_state=13)\n",
    "params = {\"min_samples_leaf\": [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2]}\n",
    "rforest = test_model(XSS_af, y, rforest, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### diabetes\n",
      "[AutoFeat] The 1 step feature engineering process could generate up to 14 features.\n",
      "[AutoFeat] With 353 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 10 transformed features from 2 original features - done.\n",
      "[feateng] Generated altogether 10 new features in 1 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 8 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 4 features after 5 feature selection runs\n",
      "[featsel] 4 features after correlation filtering\n",
      "[featsel] 4 features after noise filtering\n",
      "[AutoFeat] Computing 2 new features.\n",
      "[AutoFeat]     2/    2 new features ...done.\n",
      "[AutoFeat] Final dataframe with 4 feature columns (2 new).\n",
      "[AutoFeat] Training final regression model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "154.22297696177802\n",
      "-27796.455789 * x001**3\n",
      "813.759319 * x001\n",
      "660.920427 * x000\n",
      "0.019230 * 1/x001\n",
      "[AutoFeat] Final score: 0.4951\n",
      "[AutoFeat] Computing 2 new features.\n",
      "[AutoFeat]     2/    2 new features ...done.\n",
      "autofeat new features: 2\n",
      "autofeat MSE on training data: 3101.3306256937994\n",
      "autofeat MSE on test data: 3283.7540709552095\n",
      "autofeat R^2 on training data: 0.49512434594136356\n",
      "autofeat R^2 on test data: 0.350549887298075\n",
      "# Ridge Regression\n",
      "best params: {'alpha': 1e-05}\n",
      "best score: -3219.0763323775113\n",
      "MSE on training data: 3106.143280129417\n",
      "MSE on test data: 3288.3566859054768\n",
      "R^2 on training data: 0.4943408783433556\n",
      "R^2 on test data: 0.3496395972052164\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.05}\n",
      "best score: -3367.2177453410413\n",
      "MSE on training data: 2769.138361762169\n",
      "MSE on test data: 3332.2458551953646\n",
      "R^2 on training data: 0.5492030001603672\n",
      "R^2 on test data: 0.3409593412159425\n",
      "# SVR\n",
      "best params: {'C': 50.0}\n",
      "best score: -3468.0366248794853\n",
      "MSE on training data: 3047.086134997569\n",
      "MSE on test data: 3403.7120779306865\n",
      "R^2 on training data: 0.5039549822148535\n",
      "R^2 on test data: 0.3268249860215736\n"
     ]
    }
   ],
   "source": [
    "#autofeat regresszió 1 steppel\n",
    "print(\"####\", dsname)\n",
    "test_autofeat(XSS_af, y, units, feateng_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### diabetes\n",
      "[AutoFeat] The 2 step feature engineering process could generate up to 105 features.\n",
      "[AutoFeat] With 353 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 10 transformed features from 2 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng] Generated 54 feature combinations from 66 original feature tuples - done.\n",
      "[feateng] Generated altogether 69 new features in 2 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 38 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 4 features after 5 feature selection runs\n",
      "[featsel] 4 features after correlation filtering\n",
      "[featsel] 4 features after noise filtering\n",
      "[AutoFeat] Computing 3 new features.\n",
      "[AutoFeat]     3/    3 new features ...done.\n",
      "[AutoFeat] Final dataframe with 5 feature columns (3 new).\n",
      "[AutoFeat] Training final regression model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "-229.39397071145126\n",
      "382.426390 * exp(x000)*exp(x001)\n",
      "226.710685 * x000\n",
      "14.360619 * Abs(x001)/x001\n",
      "3.660307 * Abs(x000)/x000\n",
      "[AutoFeat] Final score: 0.4951\n",
      "[AutoFeat] Computing 3 new features.\n",
      "[AutoFeat]     3/    3 new features ...done.\n",
      "autofeat new features: 3\n",
      "autofeat MSE on training data: 3101.410664155817\n",
      "autofeat MSE on test data: 3263.0919974248973\n",
      "autofeat R^2 on training data: 0.4951113162209828\n",
      "autofeat R^2 on test data: 0.3546363644498226\n",
      "# Ridge Regression\n",
      "best params: {'alpha': 0.01}\n",
      "best score: -3237.827755833059\n",
      "MSE on training data: 3100.2624374605016\n",
      "MSE on test data: 3262.5647608883073\n",
      "R^2 on training data: 0.4952982397624466\n",
      "R^2 on test data: 0.3547406395632172\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.05}\n",
      "best score: -3225.7263163479006\n",
      "MSE on training data: 2637.736943838463\n",
      "MSE on test data: 3468.724739931382\n",
      "R^2 on training data: 0.5705942624362562\n",
      "R^2 on test data: 0.3139669949080304\n",
      "# SVR\n",
      "best params: {'C': 50.0}\n",
      "best score: -3341.5239425500768\n",
      "MSE on training data: 3047.0014489212194\n",
      "MSE on test data: 3584.9465602463456\n",
      "R^2 on training data: 0.5039687685354193\n",
      "R^2 on test data: 0.29098102437826423\n"
     ]
    }
   ],
   "source": [
    "#autofeat regresszió 2 steppel\n",
    "print(\"####\", dsname)\n",
    "test_autofeat(XSS_af, y, units, feateng_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### diabetes\n",
      "[AutoFeat] The 3 step feature engineering process could generate up to 2289 features.\n",
      "[AutoFeat] With 353 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 10 transformed features from 2 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng] Generated 252 feature combinations from 66 original feature tuples - done.\n",
      "[feateng] Step 3: transformation of new features\n",
      "[feateng] Generated 1084 transformed features from 252 original features - done.\n",
      "[feateng] Generated altogether 1442 new features in 3 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 687 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 9 features after 5 feature selection runs\n",
      "[featsel] 9 features after correlation filtering\n",
      "[featsel] 4 features after noise filtering\n",
      "[AutoFeat] Computing 3 new features.\n",
      "[AutoFeat]     3/    3 new features ...done.\n",
      "[AutoFeat] Final dataframe with 5 feature columns (3 new).\n",
      "[AutoFeat] Training final regression model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "-183.9425222488529\n",
      "357.344469 * x000\n",
      "336.113327 * exp(x000)*exp(x001)\n",
      "13.083212 * Abs(x001)/x001\n",
      "0.993389 * x001/Abs(x000)\n",
      "[AutoFeat] Final score: 0.5030\n",
      "[AutoFeat] Computing 3 new features.\n",
      "[AutoFeat]     3/    3 new features ...done.\n",
      "autofeat new features: 3\n",
      "autofeat MSE on training data: 3052.6655725570904\n",
      "autofeat MSE on test data: 3289.7123013742744\n",
      "autofeat R^2 on training data: 0.5030466875094115\n",
      "autofeat R^2 on test data: 0.34937148802286977\n",
      "# Ridge Regression\n",
      "best params: {'alpha': 0.1}\n",
      "best score: -3175.4092607835564\n",
      "MSE on training data: 3056.3379216397116\n",
      "MSE on test data: 3279.2766181101515\n",
      "R^2 on training data: 0.5024488539119035\n",
      "R^2 on test data: 0.35143542324017274\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.05}\n",
      "best score: -3206.988103062705\n",
      "MSE on training data: 2613.256873715033\n",
      "MSE on test data: 3497.0736716875904\n",
      "R^2 on training data: 0.5745794523133281\n",
      "R^2 on test data: 0.30836023614162456\n",
      "# SVR\n",
      "best params: {'C': 25.0}\n",
      "best score: -3359.4713159002567\n",
      "MSE on training data: 3031.835295615665\n",
      "MSE on test data: 3406.276239303962\n",
      "R^2 on training data: 0.5064377157370684\n",
      "R^2 on test data: 0.3263178545930695\n"
     ]
    }
   ],
   "source": [
    "#autofeat regresszió 3 steppel\n",
    "print(\"####\", dsname)\n",
    "test_autofeat(XSS_af, y, units, feateng_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
