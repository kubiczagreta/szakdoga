{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install autofeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'divide': 'ignore', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston, load_diabetes\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from autofeat import AutoFeatRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ignore all future warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "np.seterr(divide = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regr adatbeolvasó fv.\n",
    "def load_regression_dataset(name):\n",
    "    units = {}\n",
    "    if name == \"boston\":\n",
    "        X, y = load_boston(True)\n",
    "    elif name == \"diabetes\":\n",
    "        X, y = load_diabetes(True)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown dataset %r\" % name)\n",
    "    return np.array(X, dtype=float), np.array(y, dtype=float), units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#módosított modell tesztelő fv.\n",
    "def test_model(X, y, model, param_grid):\n",
    "    # load data\n",
    "    #X, y, _ = load_regression_dataset(dataset)\n",
    "    # split in training and test parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "    \n",
    "    if model.__class__.__name__ == \"SVR\":\n",
    "        sscaler = StandardScaler()\n",
    "        X_train = sscaler.fit_transform(X_train)\n",
    "        X_test = sscaler.transform(X_test)\n",
    "        \n",
    "    # train model on train split incl cross-validation for parameter selection\n",
    "    gsmodel = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "    gsmodel.fit(X_train, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"MSE on training data:\", mean_squared_error(y_train, gsmodel.predict(X_train)))\n",
    "    print(\"MSE on test data:\", mean_squared_error(y_test, gsmodel.predict(X_test)))\n",
    "    print(\"R^2 on training data:\", r2_score(y_train, gsmodel.predict(X_train)))\n",
    "    print(\"R^2 on test data:\", r2_score(y_test, gsmodel.predict(X_test)))\n",
    "    return gsmodel.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#módosított autofeat modell tesztelő fv.\n",
    "def test_autofeat(X, y, units, feateng_steps=2):\n",
    "    # load data\n",
    "    #X, y, units = load_regression_dataset(dataset)\n",
    "    # split in training and test parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "    # run autofeat\n",
    "    afreg = AutoFeatRegressor(verbose=1, feateng_steps=feateng_steps, units=units)\n",
    "    # fit autofeat on less data, otherwise ridge reg model with xval will overfit on new features\n",
    "    X_train_tr = afreg.fit_transform(X_train, y_train)\n",
    "    X_test_tr = afreg.transform(X_test)\n",
    "    print(\"autofeat new features:\", len(afreg.new_feat_cols_))\n",
    "    print(\"autofeat MSE on training data:\", mean_squared_error(y_train, afreg.predict(X_train_tr)))\n",
    "    print(\"autofeat MSE on test data:\", mean_squared_error(y_test, afreg.predict(X_test_tr)))\n",
    "    print(\"autofeat R^2 on training data:\", r2_score(y_train, afreg.predict(X_train_tr)))\n",
    "    print(\"autofeat R^2 on test data:\", r2_score(y_test, afreg.predict(X_test_tr)))\n",
    "    \n",
    "    \n",
    "    # train rreg on transformed train split incl cross-validation for parameter selection\n",
    "    print(\"# Ridge Regression\")\n",
    "    rreg = Ridge()\n",
    "    param_grid = {\"alpha\": [0.00001, 0.0001, 0.001, 0.01, 0.1, 1., 2.5, 5., 10., 25., 50., 100., 250., 500., 1000., 2500., 5000., 10000.]}\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        gsmodel = GridSearchCV(rreg, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "        gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"MSE on training data:\", mean_squared_error(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"MSE on test data:\", mean_squared_error(y_test, gsmodel.predict(X_test_tr)))\n",
    "    print(\"R^2 on training data:\", r2_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"R^2 on test data:\", r2_score(y_test, gsmodel.predict(X_test_tr)))\n",
    "    \n",
    "    \n",
    "    print(\"# Random Forest\")\n",
    "    rforest = RandomForestRegressor(n_estimators=100, random_state=13)\n",
    "    param_grid = {\"min_samples_leaf\": [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2]}\n",
    "    gsmodel = GridSearchCV(rforest, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "    gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"MSE on training data:\", mean_squared_error(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"MSE on test data:\", mean_squared_error(y_test, gsmodel.predict(X_test_tr)))\n",
    "    print(\"R^2 on training data:\", r2_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"R^2 on test data:\", r2_score(y_test, gsmodel.predict(X_test_tr)))\n",
    "    \n",
    "    \n",
    "    print(\"# SVR\")\n",
    "    svr = SVR(gamma=\"scale\")\n",
    "    param_grid = {\"C\": [1., 10., 25., 50., 100., 250.]}\n",
    "    sscaler = StandardScaler()\n",
    "    X_train_tr = sscaler.fit_transform(X_train_tr)\n",
    "    X_test_tr = sscaler.transform(X_test_tr)\n",
    "    gsmodel = GridSearchCV(svr, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "    gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"MSE on training data:\", mean_squared_error(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"MSE on test data:\", mean_squared_error(y_test, gsmodel.predict(X_test_tr)))\n",
    "    print(\"R^2 on training data:\", r2_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"R^2 on test data:\", r2_score(y_test, gsmodel.predict(X_test_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat] The 1 step feature engineering process could generate up to 91 features.\n",
      "[AutoFeat] With 506 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 60 transformed features from 13 original features - done.\n",
      "[feateng] Generated altogether 61 new features in 1 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 22 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 23 features after 5 feature selection runs\n",
      "[featsel] 21 features after correlation filtering\n",
      "[featsel] 9 features after noise filtering\n",
      "[AutoFeat] Computing 4 new features.\n",
      "[AutoFeat]     4/    4 new features ...done.\n",
      "[AutoFeat] Final dataframe with 17 feature columns (4 new).\n",
      "[AutoFeat] Training final regression model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "26.746281945465796\n",
      "41.962814 * 1/x012\n",
      "4.777565 * 1/x002\n",
      "2.181179 * x003\n",
      "-0.555992 * x010\n",
      "-0.291267 * x012\n",
      "-0.090812 * x000\n",
      "0.007442 * x011\n",
      "-0.006071 * x007**3\n",
      "0.003421 * exp(x005)\n",
      "[AutoFeat] Final score: 0.7933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(506, 17)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adatok beolvasása\n",
    "X, y, units = load_regression_dataset(\"boston\")\n",
    "#új változók generálása autofeattel\n",
    "afreg = AutoFeatRegressor(verbose=1, feateng_steps=1, units=units)\n",
    "#és a legjobbak kiválasztása\n",
    "X_af = afreg.fit_transform(X, y)\n",
    "X_af.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#randomforest illesztése a kibővített adathalmazra, hogy feature importance-t alkalmazzunk rajta\n",
    "randforreg = RandomForestRegressor(random_state=13)\n",
    "randforreg.fit(X_af, y)\n",
    "#feature importance alkalmazása és ábrázolása\n",
    "importances = randforreg.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.bar(range(X_af.shape[1]), importances[indices])\n",
    "plt.xticks(range(X_af.shape[1]), indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = []\n",
    "columns=[]\n",
    "#kiválasztom a legfontosabb featureket\n",
    "for i,v in enumerate(importances):\n",
    "    if v > 0.1:\n",
    "        select.append(i)\n",
    "for i in select:\n",
    "    columns.append(X_af.columns[i])\n",
    "#leszúkitem a fontos featurekkel az adathalmazt\n",
    "XS_af = X_af[columns]\n",
    "XS_af.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adathalmaz tesztelése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsname='boston'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### boston\n",
      "best params: {'alpha': 1e-05}\n",
      "best score: -24.050489014858318\n",
      "MSE on training data: 22.334797242311623\n",
      "MSE on test data: 19.969445653595734\n",
      "R^2 on training data: 0.7372541654143594\n",
      "R^2 on test data: 0.7556067396473051\n"
     ]
    }
   ],
   "source": [
    "#Ridge regresszió\n",
    "print(\"####\", dsname)\n",
    "rreg = Ridge()\n",
    "params = {\"alpha\": [0.00001, 0.0001, 0.001, 0.01, 0.1, 1., 2.5, 5., 10., 25., 50., 100., 250., 500., 1000., 2500., 5000., 10000., 25000., 50000., 100000.]}\n",
    "rreg = test_model(XS_af, y, rreg, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### boston\n",
      "best params: {'C': 10.0}\n",
      "best score: -23.249465043624838\n",
      "MSE on training data: 17.292913714061946\n",
      "MSE on test data: 16.18011190177037\n",
      "R^2 on training data: 0.7965667206680038\n",
      "R^2 on test data: 0.8019819693976791\n"
     ]
    }
   ],
   "source": [
    "#SVR regresszió\n",
    "print(\"####\", dsname)\n",
    "svr = SVR(gamma=\"scale\")\n",
    "params = {\"C\": [1., 10., 25., 50., 100., 250.]}\n",
    "svr = test_model(XS_af, y, svr, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### boston\n",
      "best params: {'min_samples_leaf': 0.01}\n",
      "best score: -21.444576255728133\n",
      "MSE on training data: 12.847390898639864\n",
      "MSE on test data: 16.35898987235349\n",
      "R^2 on training data: 0.8488637077252588\n",
      "R^2 on test data: 0.7997927964384283\n"
     ]
    }
   ],
   "source": [
    "#random forest regresszió\n",
    "print(\"####\", dsname)\n",
    "rforest = RandomForestRegressor(n_estimators=100, random_state=13)\n",
    "params = {\"min_samples_leaf\": [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2]}\n",
    "rforest = test_model(XS_af, y, rforest, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### boston\n",
      "[AutoFeat] The 1 step feature engineering process could generate up to 28 features.\n",
      "[AutoFeat] With 404 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 20 transformed features from 4 original features - done.\n",
      "[feateng] Generated altogether 20 new features in 1 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 10 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 7 features after 5 feature selection runs\n",
      "[featsel] 7 features after correlation filtering\n",
      "[featsel] 6 features after noise filtering\n",
      "[AutoFeat] Computing 2 new features.\n",
      "[AutoFeat]     2/    2 new features ...done.\n",
      "[AutoFeat] Final dataframe with 6 feature columns (2 new).\n",
      "[AutoFeat] Training final regression model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "46.81323864421262\n",
      "22.730499 * 1/x012\n",
      "-4.136469 * x005\n",
      "-0.732779 * x012\n",
      "0.011751 * exp(x005)\n",
      "0.000166 * x012**3\n",
      "[AutoFeat] Final score: 0.7758\n",
      "[AutoFeat] Computing 2 new features.\n",
      "[AutoFeat]     2/    2 new features ...done.\n",
      "autofeat new features: 2\n",
      "autofeat MSE on training data: 19.0619246664332\n",
      "autofeat MSE on test data: 17.49683217389327\n",
      "autofeat R^2 on training data: 0.7757561328650667\n",
      "autofeat R^2 on test data: 0.7858674729885783\n",
      "# Ridge Regression\n",
      "best params: {'alpha': 0.1}\n",
      "best score: -21.662669353062235\n",
      "MSE on training data: 19.08188684817668\n",
      "MSE on test data: 17.35351687723171\n",
      "R^2 on training data: 0.7755212984027058\n",
      "R^2 on test data: 0.7876214171499288\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.01}\n",
      "best score: -21.459659788691248\n",
      "MSE on training data: 12.848230185418252\n",
      "MSE on test data: 16.359607935138012\n",
      "R^2 on training data: 0.8488538343826602\n",
      "R^2 on test data: 0.7997852323637097\n",
      "# SVR\n",
      "best params: {'C': 25.0}\n",
      "best score: -22.732917635832596\n",
      "MSE on training data: 15.766360377764961\n",
      "MSE on test data: 15.606171093013701\n",
      "R^2 on training data: 0.8145250448933521\n",
      "R^2 on test data: 0.8090060635029779\n"
     ]
    }
   ],
   "source": [
    "#autofeat regresszió 1 steppel\n",
    "print(\"####\", dsname)\n",
    "test_autofeat(XS_af, y, units, feateng_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### boston\n",
      "[AutoFeat] The 2 step feature engineering process could generate up to 406 features.\n",
      "[AutoFeat] With 404 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 20 transformed features from 4 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng] Generated 260 feature combinations from 276 original feature tuples - done.\n",
      "[feateng] Generated altogether 286 new features in 2 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 87 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 16 features after 5 feature selection runs\n",
      "[featsel] 12 features after correlation filtering\n",
      "[featsel] 8 features after noise filtering\n",
      "[AutoFeat] Computing 6 new features.\n",
      "[AutoFeat]     6/    6 new features ...done.\n",
      "[AutoFeat] Final dataframe with 10 feature columns (6 new).\n",
      "[AutoFeat] Training final regression model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "18.312462538460736\n",
      "144566.382354 * x1x012**3/expx005\n",
      "-0.164340 * x012\n",
      "0.012969 * x005**3*sqrt(x1x012)\n",
      "0.010930 * exp(x005)\n",
      "-0.000027 * expx005*x012**2\n",
      "[AutoFeat] Final score: 0.8006\n",
      "[AutoFeat] Computing 6 new features.\n",
      "[AutoFeat]     6/    6 new features ...done.\n",
      "autofeat new features: 6\n",
      "autofeat MSE on training data: 16.95387709129392\n",
      "autofeat MSE on test data: 18.314009255035664\n",
      "autofeat R^2 on training data: 0.8005551365662027\n",
      "autofeat R^2 on test data: 0.7758665658722643\n",
      "# Ridge Regression\n",
      "best params: {'alpha': 1e-05}\n",
      "best score: -21.270569422095132\n",
      "MSE on training data: 17.53640097225888\n",
      "MSE on test data: 17.93812722256654\n",
      "R^2 on training data: 0.7937023444136841\n",
      "R^2 on test data: 0.7804667454173879\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.01}\n",
      "best score: -22.417051044488353\n",
      "MSE on training data: 12.127762359009237\n",
      "MSE on test data: 16.365862924620373\n",
      "R^2 on training data: 0.8573293946614579\n",
      "R^2 on test data: 0.7997086815520555\n",
      "# SVR\n",
      "best params: {'C': 25.0}\n",
      "best score: -23.539650265815542\n",
      "MSE on training data: 15.625956347146468\n",
      "MSE on test data: 16.26521226293\n",
      "R^2 on training data: 0.8161767533822994\n",
      "R^2 on test data: 0.800940480561095\n"
     ]
    }
   ],
   "source": [
    "#autofeat regresszió 2 steppel\n",
    "print(\"####\", dsname)\n",
    "test_autofeat(XS_af, y, units, feateng_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### boston\n",
      "[AutoFeat] The 3 step feature engineering process could generate up to 9478 features.\n",
      "[AutoFeat] With 404 data points this new feature matrix would use about 0.02 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 20 transformed features from 4 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng] Generated 1038 feature combinations from 276 original feature tuples - done.\n",
      "[feateng] Step 3: transformation of new features\n",
      "[feateng] Generated 4508 transformed features from 1038 original features - done.\n",
      "[feateng] Generated altogether 5961 new features in 3 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 2563 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 15 features after 5 feature selection runs\n",
      "[featsel] 9 features after correlation filtering\n",
      "[featsel] 5 features after noise filtering\n",
      "[AutoFeat] Computing 5 new features.\n",
      "[AutoFeat]     5/    5 new features ...done.\n",
      "[AutoFeat] Final dataframe with 9 feature columns (5 new).\n",
      "[AutoFeat] Training final regression model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "14.02889080874806\n",
      "87859.864119 * x1x012**3/expx005\n",
      "1.882352 * log(expx005**2*x1x012**3)\n",
      "-0.124282 * 1/(exp(x1x012) - log(x012))\n",
      "0.049043 * 1/(-x1x012**2 + 1/x005)\n",
      "-0.026320 * 1/(x1x012**2 + 1/expx005)\n",
      "[AutoFeat] Final score: 0.7544\n",
      "[AutoFeat] Computing 5 new features.\n",
      "[AutoFeat]     5/    5 new features ...done.\n",
      "autofeat new features: 5\n",
      "autofeat MSE on training data: 20.873234011752725\n",
      "autofeat MSE on test data: 77.9247714630089\n",
      "autofeat R^2 on training data: 0.754447948131374\n",
      "autofeat R^2 on test data: 0.04632861169813007\n",
      "# Ridge Regression\n",
      "best params: {'alpha': 25.0}\n",
      "best score: -24.179828338314902\n",
      "MSE on training data: 20.917875918769727\n",
      "MSE on test data: 72.07221554520571\n",
      "R^2 on training data: 0.753922782176679\n",
      "R^2 on test data: 0.11795429660495349\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.01}\n",
      "best score: -22.880867635392782\n",
      "MSE on training data: 12.047479662998114\n",
      "MSE on test data: 17.752527903989407\n",
      "R^2 on training data: 0.8582738377086626\n",
      "R^2 on test data: 0.7827381766515412\n",
      "# SVR\n",
      "best params: {'C': 10.0}\n",
      "best score: -23.74612394276473\n",
      "MSE on training data: 16.188902899092813\n",
      "MSE on test data: 18.91820158717605\n",
      "R^2 on training data: 0.809554268297096\n",
      "R^2 on test data: 0.7684722427401498\n"
     ]
    }
   ],
   "source": [
    "#autofeat regresszió 3 steppel\n",
    "print(\"####\", dsname)\n",
    "test_autofeat(XS_af, y, units, feateng_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
