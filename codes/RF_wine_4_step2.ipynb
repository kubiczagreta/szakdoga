{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from autofeat import AutoFeatClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ignore all future warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "np.seterr(divide = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same interface for loading all datasets\n",
    "def load_classification_dataset(name):\n",
    "    # load one of the datasets as X and y\n",
    "    units = {}\n",
    "    if name == \"iris\":\n",
    "        # sklearn iris housing dataset\n",
    "        X, y = load_iris(True)\n",
    "\n",
    "    elif name == \"wine\":\n",
    "        # sklearn wine dataset\n",
    "        X, y = load_wine(True)\n",
    "    \n",
    "    elif name == \"breast_cancer\":\n",
    "        # sklearn breast_cancer dataset\n",
    "        X, y = load_breast_cancer(True)\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown dataset %r\" % name)\n",
    "    return np.array(X, dtype=float), np.array(y, dtype=float), units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(X, y, model, param_grid):\n",
    "    # load data\n",
    "    #X, y, _ = load_classification_dataset(dataset)\n",
    "    # split in training and test parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "    \n",
    "    if model.__class__.__name__ == \"SVC\":\n",
    "        sscaler = StandardScaler()\n",
    "        X_train = sscaler.fit_transform(X_train)\n",
    "        X_test = sscaler.transform(X_test)\n",
    "    \n",
    "    # train model on train split incl cross-validation for parameter selection\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        gsmodel = GridSearchCV(model, param_grid, cv=5)\n",
    "        gsmodel.fit(X_train, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"Acc. on training data:\", accuracy_score(y_train, gsmodel.predict(X_train)))\n",
    "    print(\"Acc. on test data:\", accuracy_score(y_test, gsmodel.predict(X_test)))\n",
    "    return gsmodel.best_estimator_\n",
    "\n",
    "def test_autofeat(X, y, units, feateng_steps=2):\n",
    "    # load data\n",
    "    #X, y, units = load_classification_dataset(dataset)\n",
    "    # split in training and test parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "    # run autofeat\n",
    "    afclas = AutoFeatClassifier(verbose=1, feateng_steps=feateng_steps, units=units)\n",
    "    # fit autofeat on less data, otherwise ridge reg model with xval will overfit on new features\n",
    "    X_train_tr = afclas.fit_transform(X_train, y_train)\n",
    "    X_test_tr = afclas.transform(X_test)\n",
    "    print(\"autofeat new features:\", len(afclas.new_feat_cols_))\n",
    "    print(\"autofeat Acc. on training data:\", accuracy_score(y_train, afclas.predict(X_train_tr)))\n",
    "    print(\"autofeat Acc. on test data:\", accuracy_score(y_test, afclas.predict(X_test_tr)))\n",
    "    \n",
    "    # train rreg on transformed train split incl cross-validation for parameter selection\n",
    "    print(\"# Logistic Regression\")\n",
    "    rreg = LogisticRegression(class_weight=\"balanced\")\n",
    "    param_grid = {\"C\": np.logspace(-4, 4, 10)}\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        gsmodel = GridSearchCV(rreg, param_grid, cv=5)\n",
    "        gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"Acc. on training data:\", accuracy_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"Acc. on test data:\", accuracy_score(y_test, gsmodel.predict(X_test_tr)))\n",
    "    \n",
    "    print(\"# Random Forest\")\n",
    "    rforest = RandomForestClassifier(n_estimators=100, random_state=13)\n",
    "    param_grid = {\"min_samples_leaf\": [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2]}\n",
    "    gsmodel = GridSearchCV(rforest, param_grid, cv=5)\n",
    "    gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"Acc. on training data:\", accuracy_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"Acc. on test data:\", accuracy_score(y_test, gsmodel.predict(X_test_tr)))\n",
    "    \n",
    "    print(\"# SVC\")\n",
    "    svc = SVC(gamma=\"scale\", class_weight=\"balanced\")\n",
    "    param_grid = {\"C\": [1., 10., 25., 50., 100., 250.]}\n",
    "    sscaler = StandardScaler()\n",
    "    X_train_tr = sscaler.fit_transform(X_train_tr)\n",
    "    X_test_tr = sscaler.transform(X_test_tr)\n",
    "    gsmodel = GridSearchCV(svc, param_grid, cv=5)\n",
    "    gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"Acc. on training data:\", accuracy_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"Acc. on test data:\", accuracy_score(y_test, gsmodel.predict(X_test_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### wine\n",
      "(178, 13) [0. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "dsname = 'wine'\n",
    "print(\"####\", dsname)\n",
    "X, y, units = load_classification_dataset(dsname)\n",
    "print(X.shape, np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#randomforest illesztése a kibővített adathalmazra, hogy feature importance-t alkalmazzunk rajta\n",
    "randforclas = RandomForestClassifier(random_state=13)\n",
    "randforclas.fit(X, y)\n",
    "#feature importance alkalmazása és ábrázolása\n",
    "importances = randforclas.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.bar(range(X.shape[1]), importances[indices])\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = []\n",
    "#kiválasztom a legfontosabb featureket\n",
    "for i,v in enumerate(importances):\n",
    "    if v > 0.075:\n",
    "        select.append(i)\n",
    "XS = X[:,select]\n",
    "XS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat] The 2 step feature engineering process could generate up to 630 features.\n",
      "[AutoFeat] With 178 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 27 transformed features from 5 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng] Generated 476 feature combinations from 496 original feature tuples - done.\n",
      "[feateng] Generated altogether 504 new features in 2 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 202 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 27 features after 5 feature selection runs\n",
      "[featsel] 10 features after correlation filtering\n",
      "[featsel] 9 features after noise filtering\n",
      "[AutoFeat] Computing 7 new features.\n",
      "[AutoFeat]     7/    7 new features ...done.\n",
      "[AutoFeat] Final dataframe with 12 feature columns (7 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[-0.1519107   0.19740088 -0.04549018]\n",
      "1.650180 * x000\n",
      "0.986977 * log(x002)/x001\n",
      "0.060479 * log(x003)/x003\n",
      "0.056468 * 1/x002\n",
      "0.011992 * x004\n",
      "0.008675 * x004*log(x003)\n",
      "0.002986 * x000**3*log(x002)\n",
      "0.002211 * x000**3*sqrt(x003)\n",
      "0.001442 * sqrt(x001)/x004\n",
      "[AutoFeat] Final score: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(178, 12)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#új változók generálása autofeattel\n",
    "afclas = AutoFeatClassifier(verbose=1, feateng_steps=2, units=units)\n",
    "# fit autofeat on less data, otherwise ridge reg model with xval will overfit on new features\n",
    "XS_af = afclas.fit_transform(XS, y)\n",
    "XS_af.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWT0lEQVR4nO3df4xd5YHe8e/TAXcDScqvgbi2qZ3IIrVWiYNGDi0VbUoT2VBloCqSUQveiK2DhJXQJupOUynKqv94EUm2kSiWk7hy2gRKNlBGGzcOdbNtow2px6wDNl4vg+PgwcaehWxIi4QxfvrHOZZOLtcz587cOza8z0e6Oue85/1xjhnmmfPec+6VbSIiojx/7VwfQEREnBsJgIiIQiUAIiIKlQCIiChUAiAiolAXnOsD6MUVV1zh5cuXn+vDiIh4W9mzZ89f2h7uLH9bBcDy5cuZmJg414cREfG2IukX3cozBRQRUahWASBpraSDkiYljXXZ/88kPV2//lTSh2drK+kySU9Ieq5eXtqfU4qIiDZmDQBJQ8ADwDpgFXC7pFUd1X4O/H3bHwL+HbC1RdsxYJftlcCuejsiIhZImyuANcCk7UO2TwIPA6PNCrb/1PYv680ngaUt2o4C2+v17cAtcz+NiIjoVZsAWAIcaWxP1WVncxfw31q0vcr2MYB6eWW3ziRtlDQhaWJ6errF4UZERBttAkBdyrp+gpykj1EFwO/12vZsbG+1PWJ7ZHj4LXcxRUTEHLUJgClgWWN7KXC0s5KkDwHfAEZtv9yi7XFJi+u2i4ETvR16RETMR5sA2A2slLRC0iJgPTDerCDpauBR4A7bf9Gy7TiwoV7fADw+99OIiIhezfogmO1TkjYBO4EhYJvt/ZLurvdvAb4IXA78B0kAp+ppm65t6643A49Iugt4Abitz+cWEREz0NvpC2FGRkY81yeBl499v89HA4c339z3PiMi+k3SHtsjneV5EjgiolAJgIiIQiUAIiIKlQCIiChUAiAiolAJgIiIQiUAIiIKlQCIiChUAiAiolAJgIiIQiUAIiIKlQCIiChUAiAiolAJgIiIQiUAIiIKlQCIiChUAiAiolCtAkDSWkkHJU1KGuuy/4OSfiLpdUmfb5RfI2lv4/WqpHvrfV+S9GJj3039O62IiJjNrN8JLGkIeAD4ODAF7JY0bvvZRrVXgM8AtzTb2j4IrG708yLwWKPKV23fP68ziIiIOWlzBbAGmLR9yPZJ4GFgtFnB9gnbu4E3ZujnRuB527+Y89FGRETftAmAJcCRxvZUXdar9cBDHWWbJD0taZukS+fQZ0REzFGbAFCXMvcyiKRFwCeB7zaKHwQ+QDVFdAz48lnabpQ0IWlienq6l2EjImIGbQJgCljW2F4KHO1xnHXAU7aPnymwfdz2m7ZPA1+nmmp6C9tbbY/YHhkeHu5x2IiIOJs2AbAbWClpRf2X/HpgvMdxbqdj+kfS4sbmrcC+HvuMiIh5mPUuINunJG0CdgJDwDbb+yXdXe/fIul9wATwXuB0favnKtuvSrqI6g6iT3d0fZ+k1VTTSYe77I+IiAGaNQAAbO8AdnSUbWmsv0Q1NdSt7WvA5V3K7+jpSN8mlo99v+99Ht58c9/7jIjIk8AREYVKAEREFCoBEBFRqARAREShEgAREYVKAEREFCoBEBFRqARAREShEgAREYVKAEREFCoBEBFRqARAREShEgAREYVKAEREFCoBEBFRqARAREShEgAREYVKAEREFKpVAEhaK+mgpElJY132f1DSTyS9LunzHfsOS3pG0l5JE43yyyQ9Iem5ennp/E8nIiLamjUAJA0BDwDrgFXA7ZJWdVR7BfgMcP9ZuvmY7dW2RxplY8Au2yuBXfV2REQskDZXAGuASduHbJ8EHgZGmxVsn7C9G3ijh7FHge31+nbglh7aRkTEPLUJgCXAkcb2VF3WloEfStojaWOj/CrbxwDq5ZXdGkvaKGlC0sT09HQPw0ZExEzaBIC6lLmHMa63fS3VFNI9km7ooS22t9oesT0yPDzcS9OIiJhBmwCYApY1tpcCR9sOYPtovTwBPEY1pQRwXNJigHp5om2fERExf20CYDewUtIKSYuA9cB4m84lXSzpPWfWgU8A++rd48CGen0D8HgvBx4REfNzwWwVbJ+StAnYCQwB22zvl3R3vX+LpPcBE8B7gdOS7qW6Y+gK4DFJZ8b6ju0f1F1vBh6RdBfwAnBbf08tIiJmMmsAANjeAezoKNvSWH+Jamqo06vAh8/S58vAja2PNCIi+ipPAkdEFCoBEBFRqARAREShEgAREYVKAEREFCoBEBFRqARAREShEgAREYVKAEREFCoBEBFRqARAREShEgAREYVKAEREFCoBEBFRqARAREShEgAREYVKAEREFKpVAEhaK+mgpElJY132f1DSTyS9LunzjfJlkn4k6YCk/ZI+29j3JUkvStpbv27qzylFREQbs34lpKQh4AHg48AUsFvSuO1nG9VeAT4D3NLR/BTwOdtP1V8Ov0fSE422X7V9/7zPIiIietbmCmANMGn7kO2TwMPAaLOC7RO2dwNvdJQfs/1Uvf5r4ACwpC9HHhER89ImAJYARxrbU8zhl7ik5cBHgJ82ijdJelrSNkmXnqXdRkkTkiamp6d7HTYiIs6iTQCoS5l7GUTSu4HvAffafrUufhD4ALAaOAZ8uVtb21ttj9geGR4e7mXYiIiYQZsAmAKWNbaXAkfbDiDpQqpf/t+2/eiZctvHbb9p+zTwdaqppoiIWCBtAmA3sFLSCkmLgPXAeJvOJQn4JnDA9lc69i1ubN4K7Gt3yBER0Q+z3gVk+5SkTcBOYAjYZnu/pLvr/VskvQ+YAN4LnJZ0L7AK+BBwB/CMpL11l1+wvQO4T9Jqqumkw8Cn+3tq72zLx77f1/4Ob765r/1FxPlv1gAAqH9h7+go29JYf4lqaqjTj+n+HgK272h/mBER0W95EjgiolAJgIiIQiUAIiIKlQCIiChUAiAiolAJgIiIQiUAIiIKlQCIiChUAiAiolAJgIiIQiUAIiIKlQCIiChUAiAiolAJgIiIQiUAIiIKlQCIiChUAiAiolAJgIiIQrUKAElrJR2UNClprMv+D0r6iaTXJX2+TVtJl0l6QtJz9fLS+Z9ORES0NWsASBoCHgDWUX3R++2SVnVUewX4DHB/D23HgF22VwK76u2IiFggba4A1gCTtg/ZPgk8DIw2K9g+YXs38EYPbUeB7fX6duCWOZ5DRETMQZsAWAIcaWxP1WVtzNT2KtvHAOrlld06kLRR0oSkienp6ZbDRkTEbNoEgLqUuWX/82lbVba32h6xPTI8PNxL04iImEGbAJgCljW2lwJHW/Y/U9vjkhYD1MsTLfuMiIg+aBMAu4GVklZIWgSsB8Zb9j9T23FgQ72+AXi8/WFHRMR8XTBbBdunJG0CdgJDwDbb+yXdXe/fIul9wATwXuC0pHuBVbZf7da27noz8Iiku4AXgNv6fXIREXF2swYAgO0dwI6Osi2N9Zeopndata3LXwZu7OVgIyKif/IkcEREoRIAERGFSgBERBQqARARUagEQEREoRIAERGFSgBERBQqARARUagEQEREoRIAERGFSgBERBQqARARUahWHwYX5Vo+9v2+9nd488197S8i5i5XABERhUoAREQUKgEQEVGoBEBERKFavQksaS3w76m+1vEbtjd37Fe9/ybgNeB3bD8l6RrgvzSqvh/4ou0/lPQl4F8A0/W+L9TfHhaF6fcbzdD9zeaFGifi7WLWAJA0BDwAfByYAnZLGrf9bKPaOmBl/foo8CDwUdsHgdWNfl4EHmu0+6rt+/txIhER0Zs2U0BrgEnbh2yfBB4GRjvqjALfcuVJ4BJJizvq3Ag8b/sX8z7qiIiYtzZTQEuAI43tKaq/8merswQ41ihbDzzU0W6TpDuBCeBztn/ZObikjcBGgKuvvrrF4UacW5lqireLNlcA6lLmXupIWgR8EvhuY/+DwAeopoiOAV/uNrjtrbZHbI8MDw+3ONyIiGijTQBMAcsa20uBoz3WWQc8Zfv4mQLbx22/afs08HWqqaaIiFggbQJgN7BS0or6L/n1wHhHnXHgTlWuA35luzn9czsd0z8d7xHcCuzr+egjImLOZn0PwPYpSZuAnVS3gW6zvV/S3fX+LcAOqltAJ6luA/3UmfaSLqK6g+jTHV3fJ2k11VTR4S77IyJigFo9B1Dfn7+jo2xLY93APWdp+xpweZfyO3o60oiI6Ks8CRwRUagEQEREoRIAERGFSgBERBQqARARUagEQEREoRIAERGFSgBERBQqARARUagEQEREoRIAERGFSgBERBQqARARUahWnwYaEeeffn/1ZL52sjy5AoiIKFQCICKiUAmAiIhC5T2AiJhR3mt452p1BSBpraSDkiYljXXZL0lfq/c/Lenaxr7Dkp6RtFfSRKP8MklPSHquXl7an1OKiIg2Zg0ASUPAA8A6YBVwu6RVHdXWASvr10bgwY79H7O92vZIo2wM2GV7JbCr3o6IiAXS5gpgDTBp+5Dtk8DDwGhHnVHgW648CVwiafEs/Y4C2+v17cAtPRx3RETMU5sAWAIcaWxP1WVt6xj4oaQ9kjY26lxl+xhAvbyy2+CSNkqakDQxPT3d4nAjIqKNNgGgLmXuoc71tq+lmia6R9INPRwftrfaHrE9Mjw83EvTiIiYQZsAmAKWNbaXAkfb1rF9ZnkCeIxqSgng+Jlponp5oteDj4iIuWsTALuBlZJWSFoErAfGO+qMA3fWdwNdB/zK9jFJF0t6D4Cki4FPAPsabTbU6xuAx+d5LhER0YNZnwOwfUrSJmAnMARss71f0t31/i3ADuAmYBJ4DfhU3fwq4DFJZ8b6ju0f1Ps2A49Iugt4Abitb2cVERGzavUgmO0dVL/km2VbGusG7unS7hDw4bP0+TJwYy8HGxER/ZOPgoiIKFQCICKiUPksoIg45/r9eUOQzxxqI1cAERGFSgBERBQqARARUagEQEREoRIAERGFSgBERBQqARARUagEQEREoRIAERGFSgBERBQqARARUagEQEREoRIAERGFSgBERBSqVQBIWivpoKRJSWNd9kvS1+r9T0u6ti5fJulHkg5I2i/ps402X5L0oqS99eum/p1WRETMZtbvA5A0BDwAfByYAnZLGrf9bKPaOmBl/foo8GC9PAV8zvZT9ZfD75H0RKPtV23f37/TiYg4u3zvwG9qcwWwBpi0fcj2SeBhYLSjzijwLVeeBC6RtNj2MdtPAdj+NXAAWNLH44+IiDlqEwBLgCON7Sne+kt81jqSlgMfAX7aKN5UTxltk3Rpt8ElbZQ0IWlienq6xeFGREQbbQJAXcrcSx1J7wa+B9xr+9W6+EHgA8Bq4Bjw5W6D295qe8T2yPDwcIvDjYiINtoEwBSwrLG9FDjato6kC6l++X/b9qNnKtg+bvtN26eBr1NNNUVExAJpEwC7gZWSVkhaBKwHxjvqjAN31ncDXQf8yvYxSQK+CRyw/ZVmA0mLG5u3AvvmfBYREdGzWe8Csn1K0iZgJzAEbLO9X9Ld9f4twA7gJmASeA34VN38euAO4BlJe+uyL9jeAdwnaTXVVNFh4NN9O6uIiJjVrAEAUP/C3tFRtqWxbuCeLu1+TPf3B7B9R09HGhERfZUngSMiCtXqCiAiItp7uzxwliuAiIhCJQAiIgqVAIiIKFQCICKiUAmAiIhCJQAiIgqVAIiIKFQCICKiUAmAiIhCJQAiIgqVAIiIKFQCICKiUAmAiIhCJQAiIgqVAIiIKFQCICKiUK0CQNJaSQclTUoa67Jfkr5W739a0rWztZV0maQnJD1XLy/tzylFREQbswaApCHgAWAdsAq4XdKqjmrrgJX1ayPwYIu2Y8Au2yuBXfV2REQskDZXAGuASduHbJ8EHgZGO+qMAt9y5UngEkmLZ2k7Cmyv17cDt8zzXCIiogeyPXMF6Z8Ca23/br19B/BR25sadf4Y2Gz7x/X2LuD3gOVnayvpr2xf0ujjl7bfMg0kaSPVVQXANcDBuZ5sS1cAfzngMTLO+T3OO+lcMs75O8ZCjvO3bA93Frb5Unh1KetMjbPVadN2Rra3Alt7aTMfkiZsj2Sccsd5J51Lxjl/x1jIcc6mzRTQFLCssb0UONqyzkxtj9fTRNTLE+0POyIi5qtNAOwGVkpaIWkRsB4Y76gzDtxZ3w10HfAr28dmaTsObKjXNwCPz/NcIiKiB7NOAdk+JWkTsBMYArbZ3i/p7nr/FmAHcBMwCbwGfGqmtnXXm4FHJN0FvADc1tczm7uFmm7KOOfvOO+kc8k45+8YCzlOV7O+CRwREe9MeRI4IqJQCYCIiEIlABokHZb0jKS9kiYGOM4lkv5I0p9LOiDp7wxgjGvq8zjzelXSvf0epx5rSNKf1c+DDISkbZJOSNo3qDHqcT4raZ+k/f389+p2/JJuq8c5LanvtwJK+i1J/0fSz+pxfn8AYyyT9KP653i/pM/2e4zGWDN+JE0fx/mX9bnsk/SQpN/qU7/dfgbO7Ufi2M6rfgGHgSsWYJztwO/W64uASwY83hDwEtXDIIPo/18B3wH+eIDncANwLbBvgGP8NrAPuIjqBon/Dqwc1PEDf5vq4cY/AUYGcD4C3l2vXwj8FLiuz2MsBq6t198D/AWwagDnMgQ8D7y//n/mZwMaZwnwc+Bd9fYjwO8M8GfgPmCsXh8D/qDf5zTTK1cAC0zSe6l+EL4JYPuk7b8a8LA3As/b/kW/O5a0FLgZ+Ea/+26y/b+AVwY5BtUv5Cdtv2b7FPA/gVv70XG347d9wPbAnmx35f/WmxfWr77e9WH7mO2n6vVfAweofon2W5uPpOmXC4B3SbqA6o+Bzuee5uQsP8Pn9CNxEgC/ycAPJe2pP4JiEN4PTAP/sZ42+Yakiwc01hnrgYcG1PcfAv8aOD2g/hfSPuAGSZdLuojq1uZls7Q5r9XTc3upHrR8wvZPBzjWcuAjVFca/bYEONLYnmIAQWP7ReB+qlvTj1E90/TDfo/TcJWrZ6aol1cOcKy3SAD8puttX0v16aX3SLphAGNcQHUZ+KDtjwD/jwF+Emr9AN4nge8OoO9/DJywvafffZ8Ltg8AfwA8AfyAaprh1Dk9qHmy/abt1VRP4a+R9NuDGEfSu4HvAffafnUQQ3Qp6/s97PUc/CiwAvibwMWS/nm/xzlfJAAabB+tlyeAx6guO/ttCphq/CX2R1SBMCjrgKdsHx9A39cDn5R0mOqS/B9K+s8DGGfB2P6m7Wtt30B1uf7cuT6mfqinGf8EWNvvviVdSPXL/9u2H+13/7U2H0nTD/8I+LntadtvAI8Cf3cA45xxTj8SJwFQk3SxpPecWQc+QTUl0Fe2XwKOSLqmLroReLbf4zTczoCmf2z/G9tLbS+nmmb6H7bf1n8tSbqyXl4N/BMGN3U2cJKGJV1Sr7+L6pfbn/d5DFG9n3XA9lf62XeHNh9J0w8vANdJuqg+txup3tcYlHP7kTgL+Y7z+fyimpv/Wf3aD/zbAY61GpgAngb+K3DpgMa5CHgZ+BsL8O/3DxjsXUAPUc3JvkH11+BdAxrnf1MF8s+AGwd5/FRvME8BrwPHgZ19PpcPAX9W/5ztA744gH+vv0c1FfM0sLd+3TSg/zY3Ud1l9PyA///8faqg3Af8J+CvD/Bn4HKqL8R6rl5eNqjz6vbKR0FERBQqU0AREYVKAEREFCoBEBFRqARAREShEgAREYVKAEREFCoBEBFRqP8P3e/adkfkZhEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#randomforest illesztése a kibővített adathalmazra, hogy feature importance-t alkalmazzunk rajta\n",
    "randforclas = RandomForestClassifier(random_state=13)\n",
    "randforclas.fit(XS_af, y)\n",
    "#feature importance alkalmazása és ábrázolása\n",
    "importances = randforclas.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.bar(range(XS_af.shape[1]), importances[indices])\n",
    "plt.xticks(range(XS_af.shape[1]), indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = []\n",
    "columns=[]\n",
    "#kiválasztom a legfontosabb featureket\n",
    "for i,v in enumerate(importances):\n",
    "    if v > 0.1:\n",
    "        select.append(i)\n",
    "for i in select:\n",
    "    columns.append(XS_af.columns[i])\n",
    "XSS_af = XS_af[columns]\n",
    "XSS_af.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### wine\n",
      "best params: {'C': 2.782559402207126}\n",
      "best score: 0.9719211822660098\n",
      "Acc. on training data: 0.9788732394366197\n",
      "Acc. on test data: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"####\", dsname)\n",
    "rreg = LogisticRegression(class_weight=\"balanced\")\n",
    "params = {\"C\": np.logspace(-4, 4, 10)}\n",
    "rreg = test_model(XSS_af, y, rreg, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### wine\n",
      "best params: {'min_samples_leaf': 0.0001}\n",
      "best score: 0.9790640394088669\n",
      "Acc. on training data: 1.0\n",
      "Acc. on test data: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"####\", dsname)\n",
    "rforest = RandomForestClassifier(n_estimators=100, random_state=13)\n",
    "params = {\"min_samples_leaf\": [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2]}\n",
    "rforest = test_model(XSS_af, y, rforest, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### wine\n",
      "best params: {'C': 10.0}\n",
      "best score: 0.9790640394088669\n",
      "Acc. on training data: 0.9859154929577465\n",
      "Acc. on test data: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"####\", dsname)\n",
    "svc = SVC(gamma=\"scale\", class_weight=\"balanced\")\n",
    "params = {\"C\": [1., 10., 25., 50., 100., 250.]}\n",
    "svc = test_model(XSS_af, y, svc, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### wine\n",
      "[AutoFeat] The 1 step feature engineering process could generate up to 21 features.\n",
      "[AutoFeat] With 142 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 16 transformed features from 3 original features - done.\n",
      "[feateng] Generated altogether 16 new features in 1 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 7 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 4 features after 5 feature selection runs\n",
      "[featsel] 4 features after correlation filtering\n",
      "[featsel] 4 features after noise filtering\n",
      "[AutoFeat] Computing 1 new features.\n",
      "[AutoFeat]     1/    1 new features ...done.\n",
      "[AutoFeat] Final dataframe with 4 feature columns (1 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[-9.26681291 10.80698599 -1.54017306]\n",
      "0.988624 * log(x002)/x001\n",
      "0.009118 * x004*log(x003)\n",
      "0.002624 * x000**3*log(x002)\n",
      "0.000370 * 1/x004logx003\n",
      "[AutoFeat] Final score: 0.9789\n",
      "[AutoFeat] Computing 1 new features.\n",
      "[AutoFeat]     1/    1 new features ...done.\n",
      "autofeat new features: 1\n",
      "autofeat Acc. on training data: 0.9788732394366197\n",
      "autofeat Acc. on test data: 0.9722222222222222\n",
      "# Logistic Regression\n",
      "best params: {'C': 2.782559402207126}\n",
      "best score: 0.9719211822660098\n",
      "Acc. on training data: 0.9859154929577465\n",
      "Acc. on test data: 1.0\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.0001}\n",
      "best score: 0.9716748768472907\n",
      "Acc. on training data: 1.0\n",
      "Acc. on test data: 1.0\n",
      "# SVC\n",
      "best params: {'C': 1.0}\n",
      "best score: 0.9788177339901478\n",
      "Acc. on training data: 0.9859154929577465\n",
      "Acc. on test data: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"####\", dsname)\n",
    "test_autofeat(XSS_af, y, units, feateng_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### wine\n",
      "[AutoFeat] The 2 step feature engineering process could generate up to 231 features.\n",
      "[AutoFeat] With 142 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 16 transformed features from 3 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng] Generated 161 feature combinations from 171 original feature tuples - done.\n",
      "[feateng] Generated altogether 179 new features in 2 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 78 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 14 features after 5 feature selection runs\n",
      "[featsel] 10 features after correlation filtering\n",
      "[featsel] 7 features after noise filtering\n",
      "[AutoFeat] Computing 4 new features.\n",
      "[AutoFeat]     4/    4 new features ...done.\n",
      "[AutoFeat] Final dataframe with 7 feature columns (4 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[-2.52605710e-05  2.23106718e-05  2.94989922e-06]\n",
      "0.009355 * x004*log(x003)\n",
      "0.008837 * x000**3*log(x002)\n",
      "0.003580 * x0003logx002/logx002x001\n",
      "0.000374 * x0003logx002*sqrt(x004logx003)\n",
      "0.000340 * sqrt(logx002x001)*sqrt(x004logx003)\n",
      "0.000022 * log(x002)/x001\n",
      "[AutoFeat] Final score: 0.9859\n",
      "[AutoFeat] Computing 4 new features.\n",
      "[AutoFeat]     4/    4 new features ...done.\n",
      "autofeat new features: 4\n",
      "autofeat Acc. on training data: 0.9859154929577465\n",
      "autofeat Acc. on test data: 1.0\n",
      "# Logistic Regression\n",
      "best params: {'C': 0.0001}\n",
      "best score: 0.9716748768472907\n",
      "Acc. on training data: 0.9859154929577465\n",
      "Acc. on test data: 1.0\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.0001}\n",
      "best score: 0.9716748768472907\n",
      "Acc. on training data: 1.0\n",
      "Acc. on test data: 1.0\n",
      "# SVC\n",
      "best params: {'C': 1.0}\n",
      "best score: 0.9859605911330049\n",
      "Acc. on training data: 0.9859154929577465\n",
      "Acc. on test data: 1.0\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "print(\"####\", dsname)\n",
    "test_autofeat(XSS_af, y, units, feateng_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### wine\n",
      "[AutoFeat] The 3 step feature engineering process could generate up to 5271 features.\n",
      "[AutoFeat] With 142 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 16 transformed features from 3 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng] Generated 613 feature combinations from 171 original feature tuples - done.\n",
      "[feateng] Step 3: transformation of new features\n",
      "[feateng] Generated 2182 transformed features from 613 original features - done.\n",
      "[feateng] Generated altogether 3242 new features in 3 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 1257 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 20 features after 5 feature selection runs\n",
      "[featsel] 9 features after correlation filtering\n",
      "[featsel] 7 features after noise filtering\n",
      "[AutoFeat] Computing 5 new features.\n",
      "[AutoFeat]     5/    5 new features ...done.\n",
      "[AutoFeat] Final dataframe with 8 feature columns (5 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[-3.61103265e-01  3.60854383e-01  2.48881441e-04]\n",
      "0.069806 * log(logx002x001*x0003logx002**3)\n",
      "0.045510 * log(x0003logx002*x004logx003)\n",
      "0.008654 * x004*log(x003)\n",
      "0.005600 * x000**3*log(x002)\n",
      "0.005086 * x0003logx002/sqrt(logx002x001)\n",
      "0.002847 * exp(log(logx002x001)/logx002x001)\n",
      "0.001388 * logx002x001*exp(-logx002x001**3)\n",
      "[AutoFeat] Final score: 0.9789\n",
      "[AutoFeat] Computing 5 new features.\n",
      "[AutoFeat]     5/    5 new features ...done.\n",
      "autofeat new features: 5\n",
      "autofeat Acc. on training data: 0.9788732394366197\n",
      "autofeat Acc. on test data: 1.0\n",
      "# Logistic Regression\n",
      "best params: {'C': 0.000774263682681127}\n",
      "best score: 0.9647783251231526\n",
      "Acc. on training data: 0.9788732394366197\n",
      "Acc. on test data: 1.0\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.0001}\n",
      "best score: 0.9647783251231526\n",
      "Acc. on training data: 1.0\n",
      "Acc. on test data: 1.0\n",
      "# SVC\n",
      "best params: {'C': 1.0}\n",
      "best score: 0.9719211822660098\n",
      "Acc. on training data: 0.9859154929577465\n",
      "Acc. on test data: 1.0\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "print(\"####\", dsname)\n",
    "test_autofeat(XSS_af, y, units, feateng_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
