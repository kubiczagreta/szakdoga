{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install autofeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston, load_diabetes\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from autofeat import AutoFeatRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ignore all future warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "np.seterr(divide = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regr adatbeolvasó fv.\n",
    "def load_regression_dataset(name):\n",
    "    units = {}\n",
    "    if name == \"boston\":\n",
    "        X, y = load_boston(True)\n",
    "    elif name == \"diabetes\":\n",
    "        X, y = load_diabetes(True)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown dataset %r\" % name)\n",
    "    return np.array(X, dtype=float), np.array(y, dtype=float), units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#módosított modell tesztelő fv.\n",
    "def test_model(X, y, model, param_grid):\n",
    "    # load data\n",
    "    #X, y, _ = load_regression_dataset(dataset)\n",
    "    # split in training and test parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "    \n",
    "    if model.__class__.__name__ == \"SVR\":\n",
    "        sscaler = StandardScaler()\n",
    "        X_train = sscaler.fit_transform(X_train)\n",
    "        X_test = sscaler.transform(X_test)\n",
    "        \n",
    "    # train model on train split incl cross-validation for parameter selection\n",
    "    gsmodel = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "    gsmodel.fit(X_train, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"MSE on training data:\", mean_squared_error(y_train, gsmodel.predict(X_train)))\n",
    "    print(\"MSE on test data:\", mean_squared_error(y_test, gsmodel.predict(X_test)))\n",
    "    print(\"R^2 on training data:\", r2_score(y_train, gsmodel.predict(X_train)))\n",
    "    print(\"R^2 on test data:\", r2_score(y_test, gsmodel.predict(X_test)))\n",
    "    return gsmodel.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#módosított autofeat modell tesztelő fv.\n",
    "def test_autofeat(X, y, units, feateng_steps=2):\n",
    "    # load data\n",
    "    #X, y, units = load_regression_dataset(dataset)\n",
    "    # split in training and test parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "    # run autofeat\n",
    "    afreg = AutoFeatRegressor(verbose=1, feateng_steps=feateng_steps, units=units)\n",
    "    # fit autofeat on less data, otherwise ridge reg model with xval will overfit on new features\n",
    "    X_train_tr = afreg.fit_transform(X_train, y_train)\n",
    "    X_test_tr = afreg.transform(X_test)\n",
    "    print(\"autofeat new features:\", len(afreg.new_feat_cols_))\n",
    "    print(\"autofeat MSE on training data:\", mean_squared_error(y_train, afreg.predict(X_train_tr)))\n",
    "    print(\"autofeat MSE on test data:\", mean_squared_error(y_test, afreg.predict(X_test_tr)))\n",
    "    print(\"autofeat R^2 on training data:\", r2_score(y_train, afreg.predict(X_train_tr)))\n",
    "    print(\"autofeat R^2 on test data:\", r2_score(y_test, afreg.predict(X_test_tr)))\n",
    "    \n",
    "    \n",
    "    # train rreg on transformed train split incl cross-validation for parameter selection\n",
    "    print(\"# Ridge Regression\")\n",
    "    rreg = Ridge()\n",
    "    param_grid = {\"alpha\": [0.00001, 0.0001, 0.001, 0.01, 0.1, 1., 2.5, 5., 10., 25., 50., 100., 250., 500., 1000., 2500., 5000., 10000.]}\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        gsmodel = GridSearchCV(rreg, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "        gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"MSE on training data:\", mean_squared_error(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"MSE on test data:\", mean_squared_error(y_test, gsmodel.predict(X_test_tr)))\n",
    "    print(\"R^2 on training data:\", r2_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"R^2 on test data:\", r2_score(y_test, gsmodel.predict(X_test_tr)))\n",
    "    \n",
    "    \n",
    "    print(\"# Random Forest\")\n",
    "    rforest = RandomForestRegressor(n_estimators=100, random_state=13)\n",
    "    param_grid = {\"min_samples_leaf\": [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2]}\n",
    "    gsmodel = GridSearchCV(rforest, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "    gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"MSE on training data:\", mean_squared_error(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"MSE on test data:\", mean_squared_error(y_test, gsmodel.predict(X_test_tr)))\n",
    "    print(\"R^2 on training data:\", r2_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"R^2 on test data:\", r2_score(y_test, gsmodel.predict(X_test_tr)))\n",
    "    \n",
    "    print(\"# SVR\")\n",
    "    svr = SVR(gamma=\"scale\")\n",
    "    param_grid = {\"C\": [1., 10., 25., 50., 100., 250.]}\n",
    "    sscaler = StandardScaler()\n",
    "    X_train_tr = sscaler.fit_transform(X_train_tr)\n",
    "    X_test_tr = sscaler.transform(X_test_tr)\n",
    "\n",
    "    gsmodel = GridSearchCV(svr, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "    gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"MSE on training data:\", mean_squared_error(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"MSE on test data:\", mean_squared_error(y_test, gsmodel.predict(X_test_tr)))\n",
    "    print(\"R^2 on training data:\", r2_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"R^2 on test data:\", r2_score(y_test, gsmodel.predict(X_test_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### boston\n",
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "#adatok beolvasása\n",
    "dsname = 'boston'\n",
    "print(\"####\", dsname)\n",
    "X, y, units = load_regression_dataset(dsname)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#randomforest illesztése a kibővített adathalmazra, hogy feature importance-t alkalmazzunk rajta\n",
    "randforreg = RandomForestRegressor(random_state=13)\n",
    "randforreg.fit(X, y)\n",
    "#feature importance alkalmazása és ábrázolása\n",
    "importances = randforreg.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.bar(range(X.shape[1]), importances[indices])\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = []\n",
    "#kiválasztom a legfontosabb featureket\n",
    "for i,v in enumerate(importances):\n",
    "    if v > 0.1:\n",
    "        select.append(i)\n",
    "XS = X[:,select]\n",
    "XS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat] The 1 step feature engineering process could generate up to 14 features.\n",
      "[AutoFeat] With 506 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 11 transformed features from 2 original features - done.\n",
      "[feateng] Generated altogether 11 new features in 1 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 4 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 4 features after 5 feature selection runs\n",
      "[featsel] 4 features after correlation filtering\n",
      "[featsel] 4 features after noise filtering\n",
      "[AutoFeat] Computing 3 new features.\n",
      "[AutoFeat]     3/    3 new features ...done.\n",
      "[AutoFeat] Final dataframe with 5 feature columns (3 new).\n",
      "[AutoFeat] Training final regression model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "23.650375140807487\n",
      "33.664200 * 1/x001\n",
      "-0.688904 * x001\n",
      "0.003966 * exp(x000)\n",
      "0.000227 * x001**3\n",
      "[AutoFeat] Final score: 0.7467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(506, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#új változók generálása autofeattel\n",
    "afreg = AutoFeatRegressor(verbose=1, feateng_steps=1, units=units)\n",
    "#és a legjobbak kiválasztása\n",
    "XS_af = afreg.fit_transform(XS, y)\n",
    "XS_af.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#randomforest illesztése a kibővített adathalmazra, hogy feature importance-t alkalmazzunk rajta\n",
    "randforreg = RandomForestRegressor(random_state=13)\n",
    "randforreg.fit(XS_af, y)\n",
    "#feature importance alkalmazása és ábrázolása\n",
    "importances = randforreg.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.bar(range(XS_af.shape[1]), importances[indices])\n",
    "plt.xticks(range(XS_af.shape[1]), indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = []\n",
    "columns=[]\n",
    "#kiválasztom a legfontosabb featureket\n",
    "for i,v in enumerate(importances):\n",
    "    if v > 0.15:\n",
    "        select.append(i)\n",
    "for i in select:\n",
    "    columns.append(XS_af.columns[i])\n",
    "#leszúkitem a fontos featurekkel az adathalmazt\n",
    "XSS_af = XS_af[columns]\n",
    "XSS_af.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adathalmaz tesztelése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsname='boston'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### boston\n",
      "best params: {'alpha': 0.001}\n",
      "best score: -26.073085418883288\n",
      "MSE on training data: 24.892440783522403\n",
      "MSE on test data: 24.21647523996476\n",
      "R^2 on training data: 0.7071661292653262\n",
      "R^2 on test data: 0.7036300636077182\n"
     ]
    }
   ],
   "source": [
    "#Ridge regresszió\n",
    "print(\"####\", dsname)\n",
    "rreg = Ridge()\n",
    "params = {\"alpha\": [0.00001, 0.0001, 0.001, 0.01, 0.1, 1., 2.5, 5., 10., 25., 50., 100., 250., 500., 1000., 2500., 5000., 10000., 25000., 50000., 100000.]}\n",
    "rreg = test_model(XSS_af, y, rreg, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### boston\n",
      "best params: {'C': 10.0}\n",
      "best score: -22.463495461553716\n",
      "MSE on training data: 17.26680507272663\n",
      "MSE on test data: 16.78208251529537\n",
      "R^2 on training data: 0.7968738618828142\n",
      "R^2 on test data: 0.7946148364572914\n"
     ]
    }
   ],
   "source": [
    "#SVR regresszió\n",
    "print(\"####\", dsname)\n",
    "svr = SVR(gamma=\"scale\")\n",
    "params = {\"C\": [1., 10., 25., 50., 100., 250.]}\n",
    "svr = test_model(XSS_af, y, svr, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### boston\n",
      "best params: {'min_samples_leaf': 0.01}\n",
      "best score: -21.433132606032252\n",
      "MSE on training data: 12.84636755870303\n",
      "MSE on test data: 16.351485025051005\n",
      "R^2 on training data: 0.8488757462632787\n",
      "R^2 on test data: 0.7998846434597486\n"
     ]
    }
   ],
   "source": [
    "#random forest regresszió\n",
    "print(\"####\", dsname)\n",
    "rforest = RandomForestRegressor(n_estimators=100, random_state=13)\n",
    "params = {\"min_samples_leaf\": [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2]}\n",
    "rforest = test_model(XSS_af, y, rforest, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### boston\n",
      "[AutoFeat] The 1 step feature engineering process could generate up to 21 features.\n",
      "[AutoFeat] With 404 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 16 transformed features from 3 original features - done.\n",
      "[feateng] Generated altogether 16 new features in 1 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 8 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 6 features after 5 feature selection runs\n",
      "[featsel] 6 features after correlation filtering\n",
      "[featsel] 5 features after noise filtering\n",
      "[AutoFeat] Computing 3 new features.\n",
      "[AutoFeat]     3/    3 new features ...done.\n",
      "[AutoFeat] Final dataframe with 6 feature columns (3 new).\n",
      "[AutoFeat] Training final regression model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "18.186154993852284\n",
      "663.665031 * 1/expx000\n",
      "31.411149 * 1/x001\n",
      "-0.489545 * 1/x1x001\n",
      "0.008336 * exp(x000)\n",
      "[AutoFeat] Final score: 0.7707\n",
      "[AutoFeat] Computing 3 new features.\n",
      "[AutoFeat]     3/    3 new features ...done.\n",
      "autofeat new features: 3\n",
      "autofeat MSE on training data: 19.49518362735154\n",
      "autofeat MSE on test data: 19.166078110830142\n",
      "autofeat R^2 on training data: 0.7706592884190138\n",
      "autofeat R^2 on test data: 0.7654386406646807\n",
      "# Ridge Regression\n",
      "best params: {'alpha': 0.1}\n",
      "best score: -21.60879909385517\n",
      "MSE on training data: 19.28869827417807\n",
      "MSE on test data: 17.655895892199023\n",
      "R^2 on training data: 0.7730883754557429\n",
      "R^2 on test data: 0.7839207939773076\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.01}\n",
      "best score: -21.45679595161642\n",
      "MSE on training data: 12.841824581171744\n",
      "MSE on test data: 16.362545449748392\n",
      "R^2 on training data: 0.8489291897044708\n",
      "R^2 on test data: 0.7997492820030728\n",
      "# SVR\n",
      "best params: {'C': 10.0}\n",
      "best score: -23.250445888961075\n",
      "MSE on training data: 17.0019054926107\n",
      "MSE on test data: 16.507773110246163\n",
      "R^2 on training data: 0.7999901320017607\n",
      "R^2 on test data: 0.79797193364508\n"
     ]
    }
   ],
   "source": [
    "#autofeat regresszió 1 steppel\n",
    "print(\"####\", dsname)\n",
    "test_autofeat(XSS_af, y, units, feateng_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### boston\n",
      "[AutoFeat] The 2 step feature engineering process could generate up to 231 features.\n",
      "[AutoFeat] With 404 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 16 transformed features from 3 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng] Generated 160 feature combinations from 171 original feature tuples - done.\n",
      "[feateng] Generated altogether 178 new features in 2 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 49 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 12 features after 5 feature selection runs\n",
      "[featsel] 9 features after correlation filtering\n",
      "[featsel] 6 features after noise filtering\n",
      "[AutoFeat] Computing 5 new features.\n",
      "[AutoFeat]     5/    5 new features ...done.\n",
      "[AutoFeat] Final dataframe with 8 feature columns (5 new).\n",
      "[AutoFeat] Training final regression model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "34.583870211907\n",
      "150933.129551 * x1x001**3/expx000\n",
      "-60.732093 * exp(x1x001)/x000\n",
      "0.011094 * exp(x000)\n",
      "-0.003130 * x000**3/x1x001\n",
      "[AutoFeat] Final score: 0.7974\n",
      "[AutoFeat] Computing 5 new features.\n",
      "[AutoFeat]     5/    5 new features ...done.\n",
      "autofeat new features: 5\n",
      "autofeat MSE on training data: 17.220432592321732\n",
      "autofeat MSE on test data: 16.957671558910125\n",
      "autofeat R^2 on training data: 0.797419386247043\n",
      "autofeat R^2 on test data: 0.7924659145695426\n",
      "# Ridge Regression\n",
      "best params: {'alpha': 5000.0}\n",
      "best score: -22.408175334225614\n",
      "MSE on training data: 19.570829099065364\n",
      "MSE on test data: 15.591217686463734\n",
      "R^2 on training data: 0.7697693975289177\n",
      "R^2 on test data: 0.8091890686721508\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.01}\n",
      "best score: -22.883846375211302\n",
      "MSE on training data: 12.75304126096721\n",
      "MSE on test data: 15.95664780206295\n",
      "R^2 on training data: 0.8499736338205891\n",
      "R^2 on test data: 0.8047168034459864\n",
      "# SVR\n",
      "best params: {'C': 25.0}\n",
      "best score: -23.08771904886499\n",
      "MSE on training data: 15.593493573578854\n",
      "MSE on test data: 17.011009668293052\n",
      "R^2 on training data: 0.8165586444038051\n",
      "R^2 on test data: 0.7918131435973652\n"
     ]
    }
   ],
   "source": [
    "#autofeat regresszió 2 steppel\n",
    "print(\"####\", dsname)\n",
    "test_autofeat(XSS_af, y, units, feateng_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### boston\n",
      "[AutoFeat] The 3 step feature engineering process could generate up to 5271 features.\n",
      "[AutoFeat] With 404 data points this new feature matrix would use about 0.01 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 16 transformed features from 3 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng] Generated 630 feature combinations from 171 original feature tuples - done.\n",
      "[feateng] Step 3: transformation of new features\n",
      "[feateng] Generated 2751 transformed features from 630 original features - done.\n",
      "[feateng] Generated altogether 3690 new features in 3 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 1352 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 22 features after 5 feature selection runs\n",
      "[featsel] 12 features after correlation filtering\n",
      "[featsel] 10 features after noise filtering\n",
      "[AutoFeat] Computing 9 new features.\n",
      "[AutoFeat]     9/    9 new features ...done.\n",
      "[AutoFeat] Final dataframe with 12 feature columns (9 new).\n",
      "[AutoFeat] Training final regression model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "-3.809031453019717\n",
      "130650.073567 * x1x001**3/expx000\n",
      "5.919609 * x000\n",
      "-0.684323 * exp(sqrt(expx000) - x000**2)\n",
      "-0.194876 * 1/(x1x001 + 1/expx000)\n",
      "-0.131155 * 1/(exp(x1x001) + log(x1x001))\n",
      "0.024904 * 1/(-x1x001**2 + 1/x000)\n",
      "-0.023192 * 1/(x1x001**2 + 1/expx000)\n",
      "0.006827 * (x000 + log(x1x001))**3\n",
      "-0.001817 * (-sqrt(expx000) + x000**2)**3\n",
      "[AutoFeat] Final score: 0.8120\n",
      "[AutoFeat] Computing 9 new features.\n",
      "[AutoFeat]     9/    9 new features ...done.\n",
      "autofeat new features: 9\n",
      "autofeat MSE on training data: 15.980909607402527\n",
      "autofeat MSE on test data: 67.68949344577015\n",
      "autofeat R^2 on training data: 0.8120010946739145\n",
      "autofeat R^2 on test data: 0.17159162643779224\n",
      "# Ridge Regression\n",
      "best params: {'alpha': 10000.0}\n",
      "best score: -22.21272735305187\n",
      "MSE on training data: 19.76135459823452\n",
      "MSE on test data: 42.24502164876898\n",
      "R^2 on training data: 0.7675280617000788\n",
      "R^2 on test data: 0.4829902264936532\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.01}\n",
      "best score: -23.013571278008982\n",
      "MSE on training data: 11.50080630231367\n",
      "MSE on test data: 15.990722910692476\n",
      "R^2 on training data: 0.8647048854965809\n",
      "R^2 on test data: 0.8042997800073142\n",
      "# SVR\n",
      "best params: {'C': 25.0}\n",
      "best score: -22.145561507352816\n",
      "MSE on training data: 14.53100222491775\n",
      "MSE on test data: 17.51911771284145\n",
      "R^2 on training data: 0.8290577583700213\n",
      "R^2 on test data: 0.7855947345452213\n"
     ]
    }
   ],
   "source": [
    "#autofeat regresszió 3 steppel\n",
    "print(\"####\", dsname)\n",
    "test_autofeat(XSS_af, y, units, feateng_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
