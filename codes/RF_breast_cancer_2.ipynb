{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from autofeat import AutoFeatClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ignore all future warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "np.seterr(divide = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same interface for loading all datasets\n",
    "def load_classification_dataset(name):\n",
    "    # load one of the datasets as X and y\n",
    "    units = {}\n",
    "    if name == \"iris\":\n",
    "        # sklearn iris housing dataset\n",
    "        X, y = load_iris(True)\n",
    "\n",
    "    elif name == \"wine\":\n",
    "        # sklearn wine dataset\n",
    "        X, y = load_wine(True)\n",
    "    \n",
    "    elif name == \"breast_cancer\":\n",
    "        # sklearn breast_cancer dataset\n",
    "        X, y = load_breast_cancer(True)\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown dataset %r\" % name)\n",
    "    return np.array(X, dtype=float), np.array(y, dtype=float), units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(X, y, model, param_grid):\n",
    "    # load data\n",
    "    #X, y, _ = load_classification_dataset(dataset)\n",
    "    # split in training and test parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "    \n",
    "    if model.__class__.__name__ == \"SVC\":\n",
    "        sscaler = StandardScaler()\n",
    "        X_train = sscaler.fit_transform(X_train)\n",
    "        X_test = sscaler.transform(X_test)\n",
    "    \n",
    "    # train model on train split incl cross-validation for parameter selection\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        gsmodel = GridSearchCV(model, param_grid, cv=5)\n",
    "        gsmodel.fit(X_train, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"Acc. on training data:\", accuracy_score(y_train, gsmodel.predict(X_train)))\n",
    "    print(\"Acc. on test data:\", accuracy_score(y_test, gsmodel.predict(X_test)))\n",
    "    return gsmodel.best_estimator_\n",
    "\n",
    "def test_autofeat(X, y, units, feateng_steps=2):\n",
    "    # load data\n",
    "    #X, y, units = load_classification_dataset(dataset)\n",
    "    # split in training and test parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "    # run autofeat\n",
    "    afclas = AutoFeatClassifier(verbose=1, feateng_steps=feateng_steps, units=units)\n",
    "    # fit autofeat on less data, otherwise ridge reg model with xval will overfit on new features\n",
    "    X_train_tr = afclas.fit_transform(X_train, y_train)\n",
    "    X_test_tr = afclas.transform(X_test)\n",
    "    print(\"autofeat new features:\", len(afclas.new_feat_cols_))\n",
    "    print(\"autofeat Acc. on training data:\", accuracy_score(y_train, afclas.predict(X_train_tr)))\n",
    "    print(\"autofeat Acc. on test data:\", accuracy_score(y_test, afclas.predict(X_test_tr)))\n",
    "    \n",
    "    # train rreg on transformed train split incl cross-validation for parameter selection\n",
    "    print(\"# Logistic Regression\")\n",
    "    rreg = LogisticRegression(class_weight=\"balanced\")\n",
    "    param_grid = {\"C\": np.logspace(-4, 4, 10)}\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        gsmodel = GridSearchCV(rreg, param_grid, cv=5)\n",
    "        gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"Acc. on training data:\", accuracy_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"Acc. on test data:\", accuracy_score(y_test, gsmodel.predict(X_test_tr)))\n",
    "    \n",
    "    print(\"# Random Forest\")\n",
    "    rforest = RandomForestClassifier(n_estimators=100, random_state=13)\n",
    "    param_grid = {\"min_samples_leaf\": [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2]}\n",
    "    gsmodel = GridSearchCV(rforest, param_grid, cv=5)\n",
    "    gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"Acc. on training data:\", accuracy_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"Acc. on test data:\", accuracy_score(y_test, gsmodel.predict(X_test_tr)))\n",
    "    \n",
    "    print(\"# SVC\")\n",
    "    svc = SVC(gamma=\"scale\", class_weight=\"balanced\")\n",
    "    param_grid = {\"C\": [1., 10., 25., 50., 100., 250.]}\n",
    "    sscaler = StandardScaler()\n",
    "    X_train_tr = sscaler.fit_transform(X_train_tr)\n",
    "    X_test_tr = sscaler.transform(X_test_tr)\n",
    "    gsmodel = GridSearchCV(svc, param_grid, cv=5)\n",
    "    gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"Acc. on training data:\", accuracy_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"Acc. on test data:\", accuracy_score(y_test, gsmodel.predict(X_test_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### breast_cancer\n",
      "(569, 30) [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "dsname = 'breast_cancer'\n",
    "print(\"####\", dsname)\n",
    "X, y, _ = load_classification_dataset(dsname)\n",
    "print(X.shape, np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#randomforest illesztése a kibővített adathalmazra, hogy feature importance-t alkalmazzunk rajta\n",
    "randforclas = RandomForestClassifier(random_state=13)\n",
    "randforclas.fit(X, y)\n",
    "#feature importance alkalmazása és ábrázolása\n",
    "importances = randforclas.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.bar(range(X.shape[1]), importances[indices])\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = []\n",
    "#kiválasztom a legfontosabb featureket\n",
    "for i,v in enumerate(importances):\n",
    "    if v > 0.06:\n",
    "        select.append(i)\n",
    "XS = X[:,select]\n",
    "XS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### breast_cancer\n",
      "best params: {'C': 10000.0}\n",
      "best score: 0.9538461538461538\n",
      "Acc. on training data: 0.9538461538461539\n",
      "Acc. on test data: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "print(\"####\", dsname)\n",
    "rreg = LogisticRegression(class_weight=\"balanced\")\n",
    "params = {\"C\": np.logspace(-4, 4, 10)}\n",
    "rreg = test_model(XS, y, rreg, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### breast_cancer\n",
      "best params: {'min_samples_leaf': 0.0001}\n",
      "best score: 0.9604395604395604\n",
      "Acc. on training data: 1.0\n",
      "Acc. on test data: 0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "print(\"####\", dsname)\n",
    "rforest = RandomForestClassifier(n_estimators=100, random_state=13)\n",
    "params = {\"min_samples_leaf\": [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2]}\n",
    "rforest = test_model(XS, y, rforest, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### breast_cancer\n",
      "best params: {'C': 25.0}\n",
      "best score: 0.9670329670329669\n",
      "Acc. on training data: 0.978021978021978\n",
      "Acc. on test data: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "print(\"####\", dsname)\n",
    "svc = SVC(gamma=\"scale\", class_weight=\"balanced\")\n",
    "params = {\"C\": [1., 10., 25., 50., 100., 250.]}\n",
    "svc = test_model(XS, y, svc, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### breast_cancer\n",
      "[AutoFeat] The 1 step feature engineering process could generate up to 49 features.\n",
      "[AutoFeat] With 455 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 32 transformed features from 7 original features - done.\n",
      "[feateng] Generated altogether 35 new features in 1 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 15 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 9 features after 5 feature selection runs\n",
      "[featsel] 4 features after correlation filtering\n",
      "[featsel] 3 features after noise filtering\n",
      "[AutoFeat] Computing 2 new features.\n",
      "[AutoFeat]     2/    2 new features ...done.\n",
      "[AutoFeat] Final dataframe with 9 feature columns (2 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[19.06303694]\n",
      "353.519322 * x006**3\n",
      "1.108806 * x003\n",
      "0.273321 * 1/x005\n",
      "[AutoFeat] Final score: 0.9516\n",
      "[AutoFeat] Computing 2 new features.\n",
      "[AutoFeat]     2/    2 new features ...done.\n",
      "autofeat new features: 2\n",
      "autofeat Acc. on training data: 0.9516483516483516\n",
      "autofeat Acc. on test data: 0.9210526315789473\n",
      "# Logistic Regression\n",
      "best params: {'C': 1291.5496650148827}\n",
      "best score: 0.9538461538461538\n",
      "Acc. on training data: 0.9626373626373627\n",
      "Acc. on test data: 0.9473684210526315\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.0001}\n",
      "best score: 0.9582417582417582\n",
      "Acc. on training data: 1.0\n",
      "Acc. on test data: 0.9210526315789473\n",
      "# SVC\n",
      "best params: {'C': 25.0}\n",
      "best score: 0.9670329670329669\n",
      "Acc. on training data: 0.978021978021978\n",
      "Acc. on test data: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "print(\"####\", dsname)\n",
    "test_autofeat(XS, y, _, feateng_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### breast_cancer\n",
      "[AutoFeat] The 2 step feature engineering process could generate up to 1225 features.\n",
      "[AutoFeat] With 455 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 32 transformed features from 7 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng] Generated 714 feature combinations from 741 original feature tuples - done.\n",
      "[feateng] Generated altogether 758 new features in 2 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 219 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 9 features after 5 feature selection runs\n",
      "[featsel] 6 features after correlation filtering\n",
      "[featsel] 6 features after noise filtering\n",
      "[AutoFeat] Computing 4 new features.\n",
      "[AutoFeat]     4/    4 new features ...done.\n",
      "[AutoFeat] Final dataframe with 11 feature columns (4 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[33.52108625]\n",
      "74.939327 * x002\n",
      "12.714725 * x005/x000\n",
      "0.840960 * x003\n",
      "0.281250 * sqrt(x006)/x005\n",
      "0.096734 * x006**2/x000\n",
      "0.050811 * 1/x005\n",
      "[AutoFeat] Final score: 0.9670\n",
      "[AutoFeat] Computing 4 new features.\n",
      "[AutoFeat]     4/    4 new features ...done.\n",
      "autofeat new features: 4\n",
      "autofeat Acc. on training data: 0.967032967032967\n",
      "autofeat Acc. on test data: 0.9210526315789473\n",
      "# Logistic Regression\n",
      "best params: {'C': 21.54434690031882}\n",
      "best score: 0.9516483516483516\n",
      "Acc. on training data: 0.9560439560439561\n",
      "Acc. on test data: 0.9298245614035088\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.0001}\n",
      "best score: 0.9670329670329669\n",
      "Acc. on training data: 1.0\n",
      "Acc. on test data: 0.9385964912280702\n",
      "# SVC\n",
      "best params: {'C': 1.0}\n",
      "best score: 0.9714285714285713\n",
      "Acc. on training data: 0.9714285714285714\n",
      "Acc. on test data: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "print(\"####\", dsname)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "test_autofeat(XS, y, _, feateng_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### breast_cancer\n",
      "[AutoFeat] The 3 step feature engineering process could generate up to 29449 features.\n",
      "[AutoFeat] With 455 data points this new feature matrix would use about 0.05 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 32 transformed features from 7 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng] Generated 2805 feature combinations from 741 original feature tuples - done.\n",
      "[feateng] Step 3: transformation of new features\n",
      "[feateng] Generated 10452 transformed features from 2805 original features - done.\n",
      "[feateng] Generated altogether 15478 new features in 3 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 4529 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 23 features after 5 feature selection runs\n",
      "[featsel] 10 features after correlation filtering\n",
      "[featsel] 9 features after noise filtering\n",
      "[AutoFeat] Computing 7 new features.\n",
      "[AutoFeat]     7/    7 new features ...done.\n",
      "[AutoFeat] Final dataframe with 14 feature columns (7 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[3.2050225]\n",
      "23.685585 * Abs(x006 - 1/x003)\n",
      "18.088930 * x002\n",
      "17.200064 * x000/x005\n",
      "9.909731 * Abs(x001**2 - 1/x003)\n",
      "9.638622 * exp(x000**2 - x005**2)\n",
      "7.348982 * Abs(x006**2 - 1/x003)\n",
      "4.852408 * (-sqrt(x001) + x001)**3\n",
      "1.625670 * x003\n",
      "0.717174 * 1/(x001**3 + 1/x003)\n",
      "[AutoFeat] Final score: 0.9648\n",
      "[AutoFeat] Computing 7 new features.\n",
      "[AutoFeat]     7/    7 new features ...done.\n",
      "autofeat new features: 7\n",
      "autofeat Acc. on training data: 0.9648351648351648\n",
      "autofeat Acc. on test data: 0.9385964912280702\n",
      "# Logistic Regression\n",
      "best params: {'C': 1291.5496650148827}\n",
      "best score: 0.9582417582417582\n",
      "Acc. on training data: 0.967032967032967\n",
      "Acc. on test data: 0.9473684210526315\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.0001}\n",
      "best score: 0.9670329670329669\n",
      "Acc. on training data: 1.0\n",
      "Acc. on test data: 0.9298245614035088\n",
      "# SVC\n",
      "best params: {'C': 1.0}\n",
      "best score: 0.9736263736263735\n",
      "Acc. on training data: 0.9758241758241758\n",
      "Acc. on test data: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "print(\"####\", dsname)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "test_autofeat(XS, y, _, feateng_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
